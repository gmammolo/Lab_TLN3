{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3107bbb9",
   "metadata": {},
   "source": [
    "# Lab 3: Valutazione delle definizioni (Content-to-Form)\n",
    "\n",
    "## Obiettivo\n",
    "Implementare un sistema di ricerca onomasiologica che, partendo da definizioni testuali, identifica il synset corretto in WordNet.\n",
    "\n",
    "La ricerca onomasiologica è un processo inverso rispetto alla consultazione tradizionale di un dizionario:\n",
    "- **Approccio tradizionale (forma → contenuto)**: data una parola, trovare il suo significato\n",
    "- **Approccio onomasiologico (contenuto → forma)**: data una definizione/descrizione, trovare il termine/synset corrispondente\n",
    "\n",
    "## Contesto\n",
    "Dopo aver prodotto e analizzato definizioni per diversi concetti nel Lab 2, ora verificheremo se e quanto le definizioni prodotte siano sufficientemente informative e ben strutturate da permettere l'identificazione del synset corretto in WordNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d2136",
   "metadata": {},
   "source": [
    "## Setup iniziale\n",
    "\n",
    "Importiamo le librerie necessarie e i moduli custom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69194b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completato!\n"
     ]
    }
   ],
   "source": [
    "# Import librerie standard\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "import src.utils as utils\n",
    "\n",
    " \n",
    "# Configurazione visualizzazioni\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Assicurarsi che WordNet sia disponibile\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "print(\"Setup completato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11abf2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moduli custom importati con successo!\n"
     ]
    }
   ],
   "source": [
    "# Import moduli custom\n",
    "from importlib import reload\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import src.content_to_form as ctf\n",
    "import src.evaluation as evaluation\n",
    "import src.wordnet_helpers as wnh\n",
    "\n",
    "# Reload per sviluppo\n",
    "reload(ctf)\n",
    "reload(evaluation)\n",
    "reload(wnh)\n",
    "\n",
    "print(\"Moduli custom importati con successo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15670a62",
   "metadata": {},
   "source": [
    "## 1. Caricamento delle definizioni\n",
    "\n",
    "Carichiamo le definizioni prodotte nel Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "340e31e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del dataset: (38, 4)\n",
      "\n",
      "Concetti nel dataset: ['Pantalone', 'Microscopio', 'Pericolo', 'Euristica']\n",
      "\n",
      "Prime definizioni per ogni concetto:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pantalone</th>\n",
       "      <th>Microscopio</th>\n",
       "      <th>Pericolo</th>\n",
       "      <th>Euristica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indumento che si indossa sulla parte inferiore...</td>\n",
       "      <td>Strumento scientifico atto a osservare il mond...</td>\n",
       "      <td>Situazione o Evento che può mettere a rischio ...</td>\n",
       "      <td>Metodo matematico e statistico per risolvere u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indumento per la parte inferiore del corpo umano</td>\n",
       "      <td>Strumento scientifico per l'osservazione di mi...</td>\n",
       "      <td>Situazione potenzialmente rischiosa</td>\n",
       "      <td>Strategia di ricerca nello spazio degli stati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indumento per le gambe, diviso per ogni gamba ...</td>\n",
       "      <td>Dispositivo ottico o elettronico per ispeziona...</td>\n",
       "      <td>Situazione in cui si teme per la propria o alt...</td>\n",
       "      <td>Strategia di ricerca che permette di stimare i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abito indossato sulle gambe</td>\n",
       "      <td>strumento dotato di lenti che permette di visu...</td>\n",
       "      <td>condizione che può causare danni alle persone ...</td>\n",
       "      <td>regola che permette di approssimare una soluzi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capo di abbigliamento per le gambe</td>\n",
       "      <td>strumento per osservare da vicino cose molto p...</td>\n",
       "      <td>Evento che minaccia la sicurezza di una persona</td>\n",
       "      <td>La metodologia di ricerca di fatti o verità, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Pantalone  \\\n",
       "0  Indumento che si indossa sulla parte inferiore...   \n",
       "1   Indumento per la parte inferiore del corpo umano   \n",
       "2  Indumento per le gambe, diviso per ogni gamba ...   \n",
       "3                        abito indossato sulle gambe   \n",
       "4                 capo di abbigliamento per le gambe   \n",
       "\n",
       "                                         Microscopio  \\\n",
       "0  Strumento scientifico atto a osservare il mond...   \n",
       "1  Strumento scientifico per l'osservazione di mi...   \n",
       "2  Dispositivo ottico o elettronico per ispeziona...   \n",
       "3  strumento dotato di lenti che permette di visu...   \n",
       "4  strumento per osservare da vicino cose molto p...   \n",
       "\n",
       "                                            Pericolo  \\\n",
       "0  Situazione o Evento che può mettere a rischio ...   \n",
       "1                Situazione potenzialmente rischiosa   \n",
       "2  Situazione in cui si teme per la propria o alt...   \n",
       "3  condizione che può causare danni alle persone ...   \n",
       "4    Evento che minaccia la sicurezza di una persona   \n",
       "\n",
       "                                           Euristica  \n",
       "0  Metodo matematico e statistico per risolvere u...  \n",
       "1      Strategia di ricerca nello spazio degli stati  \n",
       "2  Strategia di ricerca che permette di stimare i...  \n",
       "3  regola che permette di approssimare una soluzi...  \n",
       "4  La metodologia di ricerca di fatti o verità, o...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caricare dataset definizioni\n",
    "definitions_df = pd.read_csv(\"data/dataset_definizioni_Lab2.csv\", sep=';')\n",
    "\n",
    "# Il dataset ha una struttura particolare: ogni colonna è un concetto,\n",
    "# ogni riga è una definizione diversa per quel concetto\n",
    "print(f\"Shape del dataset: {definitions_df.shape}\")\n",
    "print(f\"\\nConcetti nel dataset: {list(definitions_df.columns)}\")\n",
    "print(f\"\\nPrime definizioni per ogni concetto:\")\n",
    "definitions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082413e",
   "metadata": {},
   "source": [
    "## Implementazione ricerca onomasiologica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6378a",
   "metadata": {},
   "source": [
    "### UPDATE\n",
    "I primi tentativi di implementazione della ricerca onomasiologica sono stati completati ma con scarsi risultati. Per questo motivo ho deciso di provare un approccio più di reverse engineering, cercando di capire come ottimizzare la ricerca onomasiologica partendo dalle definizioni stesse.\n",
    "\n",
    "Di seguito, mostro i passaggi che ho seguito per ottimizzare la ricerca onomasiologica, partendo dalle definizioni e arrivando alla ricerca dei synset in WordNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc5a123",
   "metadata": {},
   "source": [
    "### A. Analisi dell'algoritmo di similarità.\n",
    "Partendo da una definizione di microscopio presa dal vocabolario (in inglese), testo la similarità tra il synset di microscopio e i synset ottenuti dai precedenti tentativi di ricerca onomasiologica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33078c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after preprocessing: ['device', 'us', 'lens', 'make', 'small', 'object', 'look', 'larger', 'scientifically', 'examined', 'studied']\n",
      "Ranked Synsets by Similarity (Jaccard):\n",
      "stroboscope.n.01: 0.2069\n",
      "microscope.n.01: 0.1944\n",
      "fresnel_lens.n.01: 0.1515\n",
      "lens.n.01: 0.1200\n",
      "lift.n.06: 0.1200\n",
      "device.n.01: 0.0714\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Ranked Synsets by Similarity (Cosine):\n",
      "microscope.n.01: 0.3731\n",
      "stroboscope.n.01: 0.3693\n",
      "fresnel_lens.n.01: 0.2901\n",
      "lens.n.01: 0.2194\n",
      "lift.n.06: 0.2194\n",
      "device.n.01: 0.1383\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from importlib import reload\n",
    "import src.content_to_form as ctf\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "reload(ctf)\n",
    "definition = \"a device that uses lenses to make very small objects look larger, so that they can be scientifically examined and studied\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = wnh.old_extract_keywords(definition, stop_words)\n",
    "print(f\"Tokens after preprocessing: {tokens}\")\n",
    "\n",
    "candidates = [\n",
    "    \"microscope.n.01\",\n",
    "    \"lens.n.01\",\n",
    "    \"stroboscope.n.01\",\n",
    "    \"device.n.01\",\n",
    "    \"lift.n.06\",\n",
    "    \"fresnel_lens.n.01\",\n",
    "]      \n",
    "\n",
    "ranked = ctf.rank_synsets_by_similarity(tokens, candidates, similarity_method=\"jaccard\")\n",
    "print(\"Ranked Synsets by Similarity (Jaccard):\")\n",
    "for synset, score in ranked:\n",
    "    print(f\"{synset.name()}: {score:.4f}\")\n",
    "    \n",
    "print (\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "ranked = ctf.rank_synsets_by_similarity(tokens, candidates, similarity_method=\"cosine\")\n",
    "print(\"Ranked Synsets by Similarity (Cosine):\")\n",
    "for synset, score in ranked:\n",
    "    print(f\"{synset.name()}: {score:.4f}\")\n",
    "print (\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce61492",
   "metadata": {},
   "source": [
    "Come si può vedere, i primi problemi nascono già a livello di calcolo della similarità:\n",
    "Ci sono termini che sono molto vicini alla definizione, addirittura più vicini della parola corretta.\n",
    "Questo è un problema che si presenterà spesso e va tenuto conto. \n",
    "Anche quando si ottiene la parola corretta, la distanza dalle altre parole è molto bassa.\n",
    "Nel risultato finale (quello mostrato in precedenza) non è particolarmente problematico in quanto i termini vicini hanno comunque una certa attinenza con la definizione.\n",
    "\n",
    "QUesto risultato è stato ottenuto con un affinamento del processo di estrazione dei token dalle definizioni del senso dal wordnet. Non è possibile dare una risposta definitiva su quale sia la variante migliore, ma è possibile fare alcune considerazioni sul risultato che questo è il migliore ottenuto con il synset `microscope.n.01` come target.\n",
    "In questo caso, la variante più efficace di definizione si è dimostrata quella che include tutto:\n",
    "-  lemmi,\n",
    "-  gloss,\n",
    "-  esempi,\n",
    "-  domini\n",
    "-  termini provenienti da relazioni (iperonimi, meronimi, similar_tos, ecc.)\n",
    "\n",
    "Di seguito i token estratti dal synset di `microscope.n.01`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8697c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens extracted from synset 'microscope.n.01': ['microscope', 'magnifier', 'image', 'small', 'object', 'invention', 'microscope', 'led', 'discovery', 'cell', 'camera', 'lucida', 'magnifier', 'optical', 'device', 'consisting', 'attachment', 'enables', 'observer', 'view', 'simultaneously', 'image', 'drawing', 'surface', 'sketching', 'scientific', 'instrument', 'magnifies', 'image', 'look', 'use', 'scientifically', 'study', 'studied', 'examine', 'examined', 'device']\n"
     ]
    }
   ],
   "source": [
    "synset = wn.synset(\"microscope.n.01\")\n",
    "st= wnh.synset_to_tokens(synset, stop_words=set(stopwords.words('english')), include_relations=True, rel_depth=1)\n",
    "print(f\"Tokens extracted from synset 'microscope.n.01': {st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6e999",
   "metadata": {},
   "source": [
    "### B. Implementazione della ricerca onomasiologica di Test\n",
    "Proseguo implementando la ricerca onomasiologica guidata: il test sarà sempre la parola microscopio, ma questa volta cercerò di raggiungerla partendo effettivamente dalla definizione.\n",
    "\n",
    "Inizialmente era stato implementato un algoritmo di ricerca onomasiologica che si basava su una ricerca a profondità limitata nei synset collegati ai synset candidati, con alcuni sistemi di ottimizzazione come troncare via i synset al di sotto di una certa soglia di similarità con la definizione. Tuttavia questo approccio si è rivelato inefficace, in quanto per raggiungere il synset di microscopio era necessario passare per alcuni synset che avevano una similarità *molto bassa* con la definizione, e quindi venivano scartati.\n",
    "\n",
    "L'algoritmo finale quindi risulta più pesante, ma porta a risultati decisamente migliori:\n",
    "Sono state rimosse tutte le ottimizzazioni che scartavano i synset a bassa similarità.\n",
    "Si effettua ora una ricerca e raccolta di tutti i synset che sono iperonomi dei synset candidati, per poi effettuare un ranking di tutti i synset raccolti.\n",
    "\n",
    "Non è ancora formalmente dimostrato che il seguente algoritmo termini per conclusione dei synset validi.\n",
    "La sua terminazione dipende principalmente dalla struttura di Wordnet stesso e dall'assunto che dopo un tot di passaggi (circa 20), l'algoritmo non trova più iperonimi non visitati.\n",
    "Questa incertezza di non terminazione è però limitata da `deep_search` che lo limita a un numero massimo di iterazioni per evitare loop infiniti. Tale comportamento mi risulta un compromesso accettabile, in quanto non ho alcun modo per sapere a priori se ho già raggiunto il synset corretto (anche perchè spesso, per definizioni più corte e generiche, capiterà di trovare dei synset che presentano una similarità maggiore del goal o che il goal si trovi molto lontano dalle parole usate).\n",
    "\n",
    "In virtù della seguente analisi, ho ritenuto accettabile una ricerca quanto più approfondita sui synset raggiungibile con un limite massimo di controllo sulla ricerca e sperare che il synset sia tra quelli raggiunti: Se il goal è troppo lontano dalla definizione sarebbe comunque troppo esoso da raggiungere e vorrebbe dire che la definizione è cosi generica che verrebbero trovate comunque molte parole più vicine alla definizione ma lontane dal goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be226d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after preprocessing: ['device', 'us', 'lens', 'make', 'small', 'object', 'look', 'larger', 'scientifically', 'examined', 'studied']\n",
      "Top 10 synset candidati (Jaccard Similarity):\n",
      "\n",
      "1. stroboscope.n.01 (score: 0.207)\n",
      "   Definizione: scientific instrument that provides a flashing light synchronized with the periodic movement of an object; can make moving object appear stationary\n",
      "   Lemmi: stroboscope, strobe, strobe_light\n",
      "   Iperonimo: scientific_instrument.n.01\n",
      "\n",
      "2. light_microscope.n.01 (score: 0.200)\n",
      "   Definizione: microscope consisting of an optical instrument that magnifies the image of an object\n",
      "   Lemmi: light_microscope\n",
      "   Iperonimo: microscope.n.01\n",
      "\n",
      "3. microscope.n.01 (score: 0.194)\n",
      "   Definizione: magnifier of the image of small objects\n",
      "   Lemmi: microscope\n",
      "   Iperonimo: magnifier.n.01\n",
      "\n",
      "4. tachistoscope.n.01 (score: 0.192)\n",
      "   Definizione: scientific instrument used by psychologists; presents visual stimuli for brief exposures\n",
      "   Lemmi: tachistoscope, t-scope\n",
      "   Iperonimo: scientific_instrument.n.01\n",
      "\n",
      "5. magnifier.n.01 (score: 0.190)\n",
      "   Definizione: a scientific instrument that magnifies an image\n",
      "   Lemmi: magnifier\n",
      "   Iperonimo: scientific_instrument.n.01\n",
      "\n",
      "6. ultramicroscope.n.01 (score: 0.185)\n",
      "   Definizione: light microscope that uses scattered light to show particles too small to see with ordinary microscopes\n",
      "   Lemmi: ultramicroscope, dark-field_microscope\n",
      "   Iperonimo: light_microscope.n.01\n",
      "\n",
      "7. scientifically.r.01 (score: 0.167)\n",
      "   Definizione: with respect to science; in a scientific way\n",
      "   Lemmi: scientifically\n",
      "\n",
      "8. research.v.01 (score: 0.167)\n",
      "   Definizione: attempt to find out in a systematically and scientific manner\n",
      "   Lemmi: research\n",
      "   Iperonimo: investigate.v.01\n",
      "\n",
      "9. pragmatics.n.01 (score: 0.167)\n",
      "   Definizione: the study of language use\n",
      "   Lemmi: pragmatics\n",
      "   Iperonimo: linguistics.n.01\n",
      "\n",
      "10. experimental_psychology.n.01 (score: 0.167)\n",
      "   Definizione: the branch of psychology that uses experimental methods to study psychological issues\n",
      "   Lemmi: experimental_psychology, psychonomics\n",
      "   Iperonimo: psychology.n.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from importlib import reload\n",
    "import src.content_to_form as ctf\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "reload(ctf)\n",
    "definition = \"a device that uses lenses to make very small objects look larger, so that they can be scientifically examined and studied\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = wnh.old_extract_keywords(definition, stop_words)\n",
    "print(f\"Tokens after preprocessing: {tokens}\")\n",
    "\n",
    "\n",
    "# Cercare synset candidati usando il sistema content-to-form (aumentare a 30 candidati)\n",
    "candidates_en = ctf.search_synset_from_definition(\n",
    "    definition,\n",
    "    max_results=200,\n",
    "    DEBUG=0,\n",
    "    deep_search=6,\n",
    "    similarity_method=\"jaccard\",\n",
    "    extract_method=\"old\",\n",
    ")\n",
    "\n",
    "c=10\n",
    "\n",
    "print(f\"Top {c} synset candidati (Jaccard Similarity):\\n\")\n",
    "for i, (synset, score) in enumerate(candidates_en[:c], 1):\n",
    "    print(f\"{i}. {synset.name()} (score: {score:.3f})\")\n",
    "    print(f\"   Definizione: {synset.definition()}\")\n",
    "    print(f\"   Lemmi: {', '.join([l.name() for l in synset.lemmas()][:5])}\")\n",
    "    if synset.hypernyms():\n",
    "        print(f\"   Iperonimo: {synset.hypernyms()[0].name()}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1464a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after preprocessing: ['device', 'us', 'lens', 'make', 'small', 'object', 'look', 'larger', 'scientifically', 'examined', 'studied']\n",
      "Top 5 synset candidati (Cosine Similarity):\n",
      "\n",
      "1. microscope.n.01 (score: 0.373)\n",
      "   Definizione: magnifier of the image of small objects\n",
      "   Lemmi: microscope\n",
      "   Iperonimo: magnifier.n.01\n",
      "\n",
      "2. stroboscope.n.01 (score: 0.369)\n",
      "   Definizione: scientific instrument that provides a flashing light synchronized with the periodic movement of an object; can make moving object appear stationary\n",
      "   Lemmi: stroboscope, strobe, strobe_light\n",
      "   Iperonimo: scientific_instrument.n.01\n",
      "\n",
      "3. light_microscope.n.01 (score: 0.346)\n",
      "   Definizione: microscope consisting of an optical instrument that magnifies the image of an object\n",
      "   Lemmi: light_microscope\n",
      "   Iperonimo: microscope.n.01\n",
      "\n",
      "4. tachistoscope.n.01 (score: 0.337)\n",
      "   Definizione: scientific instrument used by psychologists; presents visual stimuli for brief exposures\n",
      "   Lemmi: tachistoscope, t-scope\n",
      "   Iperonimo: scientific_instrument.n.01\n",
      "\n",
      "5. ultramicroscope.n.01 (score: 0.329)\n",
      "   Definizione: light microscope that uses scattered light to show particles too small to see with ordinary microscopes\n",
      "   Lemmi: ultramicroscope, dark-field_microscope\n",
      "   Iperonimo: light_microscope.n.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from importlib import reload\n",
    "import src.content_to_form as ctf\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "reload(ctf)\n",
    "definition = \"a device that uses lenses to make very small objects look larger, so that they can be scientifically examined and studied\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = wnh.old_extract_keywords(definition, stop_words)\n",
    "print(f\"Tokens after preprocessing: {tokens}\")\n",
    "\n",
    "# Cercare synset candidati usando il sistema content-to-form (aumentare a 30 candidati)\n",
    "candidates_en = ctf.search_synset_from_definition(\n",
    "    definition,\n",
    "    max_results=200,\n",
    "    DEBUG=0,\n",
    "    deep_search=6,\n",
    "    similarity_method=\"cosine\",\n",
    "    extract_method=\"old\",\n",
    ")\n",
    "\n",
    "c=5\n",
    "\n",
    "print(f\"Top {c} synset candidati (Cosine Similarity):\\n\")\n",
    "for i, (synset, score) in enumerate(candidates_en[:c], 1):\n",
    "    print(f\"{i}. {synset.name()} (score: {score:.3f})\")\n",
    "    print(f\"   Definizione: {synset.definition()}\")\n",
    "    print(f\"   Lemmi: {', '.join([l.name() for l in synset.lemmas()][:5])}\")\n",
    "    if synset.hypernyms():\n",
    "        print(f\"   Iperonimo: {synset.hypernyms()[0].name()}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c1ae5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2269df0",
   "metadata": {},
   "source": [
    "### Elefante nella stanza: l'Italiano\n",
    "\n",
    "Finora ho lavorato esclusivamente con WordNet in Inglese, e le definizioni prodotte sono in Inglese.\n",
    "Questo è un limite importante, in quanto il vocabolario di partenza è in Italiano, e quindi le definizioni prodotte sono in Italiano.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96bb7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after preprocessing: ['device', 'us', 'lens', 'make', 'small', 'object', 'look', 'larger', 'scientifically', 'examined', 'studied']\n",
      "English Tokens after translation: ['instrument', 'let', 'get', 'image', 'elaborate', 'object', 'small', 'unwrap', 'detail', 'invisible']\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Ranked Synsets by Similarity (Jaccard):\n",
      "microscope.n.01: 0.1053\n",
      "fence.v.02: 0.0588\n",
      "periscope.n.01: 0.0435\n",
      "receive.v.02: 0.0263\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Ranked Synsets by Similarity (Cosine):\n",
      "microscope.n.01: 0.2236\n",
      "fence.v.02: 0.1118\n",
      "periscope.n.01: 0.0845\n",
      "receive.v.02: 0.0587\n",
      "\n",
      "================================================================================\n",
      "\n",
      "synsets  di invisibile: []\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from importlib import reload\n",
    "import src.content_to_form as ctf\n",
    "import src.wordnet_helpers as wnh\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "reload(wnh)\n",
    "reload(ctf)\n",
    "definition = \"Strumento che permette di ottenere immagini ingrandite di oggetti molto piccoli rivelando dettagli altrimenti invisibili.\"\n",
    "english_tokens = wnh.translate_tokens(definition, lang='ita', DEBUG=0)\n",
    "print(f\"Tokens after preprocessing: {tokens}\")\n",
    "print (f\"English Tokens after translation: {english_tokens}\")\n",
    "\n",
    "candidates = [\n",
    "    \"microscope.n.01\",\n",
    "    \"receive.v.02\",\n",
    "    \"fence.v.02\",\n",
    "    \"periscope.n.01\",\n",
    "    \n",
    "]      \n",
    "\n",
    "print (\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "ranked = ctf.rank_synsets_by_similarity(english_tokens, candidates, similarity_method=\"jaccard\", lang='ita', DEBUG=0)\n",
    "print(\"Ranked Synsets by Similarity (Jaccard):\")\n",
    "for synset, score in ranked:\n",
    "    print(f\"{synset.name()}: {score:.4f}\")\n",
    "    \n",
    "print (\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "ranked = ctf.rank_synsets_by_similarity(english_tokens, candidates, similarity_method=\"cosine\", lang='ita', DEBUG=0)\n",
    "print(\"Ranked Synsets by Similarity (Cosine):\")\n",
    "for synset, score in ranked:\n",
    "    print(f\"{synset.name()}: {score:.4f}\")\n",
    "print (\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"synsets  di invisibile: {wn.synsets('invisibile', lang='ita')}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485af610",
   "metadata": {},
   "source": [
    "E siamo arrivati a un punto di rottura: la ricerca onomasiologica in Italiano è decisamente più complessa, in quanto WordNet in Italiano è molto meno ricco di relazioni e definizioni rispetto a quello in Inglese.\n",
    "\n",
    "Già in fase di estrazione dei token dalla definizione, i synset candidati spesso erano lemmi non riconosciuti dallo stesso WordNet, in quanto il synset è mappato con il maschile, singolare, etc, mentre le definizioni ottenuti non rispettavano questa forma. (`wnh.old_extract_keywords`)\n",
    "\n",
    "Il problema è stato parzialmente risolto passando a SpaCY. Con SpaCY è stato possibile estrarre lemmi più vicini a quelli presenti in WordNet, e quindi ottenere dei synset candidati più vicini alla definizione. Tuttavia, anche con questo approccio, i risultati sono stati decisamente inferiori rispetto a quelli ottenuti con WordNet in Inglese.\n",
    "\n",
    "Il motivo è che alcuni token (anche chiave per la definizione) non sono presenti in WordNet in Italiano.\n",
    "Un esempio critico sono: ingrandito, invisibile, rivelira.\n",
    "\n",
    "Si applica un workaround: i token estratti dalla definizione in Italiano non riconosciuti,  vengono tradotti manualmente in Inglese, e poi si procede con la ricerca onomasiologica in Inglese.\n",
    "\n",
    "Tutta questa serie di ottimizzazioni e workaround hanno permesso all'esempio di funzionare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438a36ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definizione: Strumento che permette di ottenere immagini ingrandite di oggetti molto piccoli rivelando dettagli altrimenti invisibili.\n",
      "Tokens after preprocessing: ['instrument', 'let', 'get', 'image', 'elaborate', 'object', 'small', 'unwrap', 'detail', 'invisible']\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Ranked Synsets by Similarity (Jaccard):\n",
      "microscope.n.01: 0.1053\n",
      "fence.v.02: 0.0588\n",
      "periscope.n.01: 0.0435\n",
      "receive.v.02: 0.0263\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Ranked Synsets by Similarity (Cosine):\n",
      "microscope.n.01: 0.2236\n",
      "fence.v.02: 0.1118\n",
      "periscope.n.01: 0.0845\n",
      "receive.v.02: 0.0587\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from importlib import reload\n",
    "import src.content_to_form as ctf\n",
    "import src.wordnet_helpers as wnh\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "reload(wnh)\n",
    "reload(ctf)\n",
    "definition = \"Strumento che permette di ottenere immagini ingrandite di oggetti molto piccoli rivelando dettagli altrimenti invisibili.\"\n",
    "print (f\"Definizione: {definition}\")\n",
    "stop_words = set(stopwords.words('italian'))\n",
    "tokens = wnh.translate_tokens(\n",
    "    sentence=definition,\n",
    "    lang='ita', \n",
    "    DEBUG=0\n",
    ")\n",
    "print(f\"Tokens after preprocessing: {tokens}\")\n",
    "\n",
    "candidates = [\n",
    "    \"microscope.n.01\",\n",
    "    \"receive.v.02\",\n",
    "    \"fence.v.02\",\n",
    "    \"periscope.n.01\",\n",
    "    \n",
    "]      \n",
    "\n",
    "print (\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "ranked = ctf.rank_synsets_by_similarity(tokens, candidates, similarity_method=\"jaccard\", lang='eng', DEBUG=0)\n",
    "print(\"Ranked Synsets by Similarity (Jaccard):\")\n",
    "for synset, score in ranked:\n",
    "    print(f\"{synset.name()}: {score:.4f}\")\n",
    "    \n",
    "print (\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "ranked = ctf.rank_synsets_by_similarity(tokens, candidates, similarity_method=\"cosine\", lang='eng', DEBUG=0)\n",
    "print(\"Ranked Synsets by Similarity (Cosine):\")\n",
    "for synset, score in ranked:\n",
    "    print(f\"{synset.name()}: {score:.4f}\")\n",
    "print (\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3aae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definizione: Strumento che permette di ottenere immagini ingrandite di oggetti molto piccoli rivelando dettagli altrimenti invisibili.\n",
      "Top 10 synset candidati (Cosine Similarity):\n",
      "\n",
      "1. light_microscope.n.01 (score: 0.290)\n",
      "   Definizione: microscope consisting of an optical instrument that magnifies the image of an object\n",
      "   Lemmi: light_microscope\n",
      "   Iperonimo: microscope.n.01\n",
      "\n",
      "2. angioscope.n.01 (score: 0.286)\n",
      "   Definizione: a modified microscope used to study capillary vessels\n",
      "   Lemmi: angioscope\n",
      "   Iperonimo: microscope.n.01\n",
      "\n",
      "3. ultramicroscope.n.01 (score: 0.276)\n",
      "   Definizione: light microscope that uses scattered light to show particles too small to see with ordinary microscopes\n",
      "   Lemmi: ultramicroscope, dark-field_microscope\n",
      "   Iperonimo: light_microscope.n.01\n",
      "\n",
      "4. binocular_microscope.n.01 (score: 0.254)\n",
      "   Definizione: a light microscope adapted to the use of both eyes\n",
      "   Lemmi: binocular_microscope\n",
      "   Iperonimo: light_microscope.n.01\n",
      "\n",
      "5. collimator.n.01 (score: 0.245)\n",
      "   Definizione: a small telescope attached to a large telescope to use in setting the line of the larger one\n",
      "   Lemmi: collimator\n",
      "   Iperonimo: telescope.n.01\n",
      "\n",
      "6. epidiascope.n.01 (score: 0.237)\n",
      "   Definizione: an optical projector that gives images of both transparent and opaque objects\n",
      "   Lemmi: epidiascope\n",
      "   Iperonimo: projector.n.02\n",
      "\n",
      "7. microscope.n.01 (score: 0.224)\n",
      "   Definizione: magnifier of the image of small objects\n",
      "   Lemmi: microscope\n",
      "   Iperonimo: magnifier.n.01\n",
      "\n",
      "8. pinprick.n.02 (score: 0.224)\n",
      "   Definizione: small puncture (as if made by a pin)\n",
      "   Lemmi: pinprick\n",
      "   Iperonimo: puncture.n.02\n",
      "\n",
      "9. transit_instrument.n.01 (score: 0.218)\n",
      "   Definizione: a telescope mounted on an axis running east and west and used to time the transit of a celestial body across the meridian\n",
      "   Lemmi: transit_instrument\n",
      "   Iperonimo: telescope.n.01\n",
      "\n",
      "10. inset.n.01 (score: 0.212)\n",
      "   Definizione: a small picture inserted within the bounds or a larger one\n",
      "   Lemmi: inset\n",
      "   Iperonimo: picture.n.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import src.content_to_form as ctf\n",
    "import src.wordnet_helpers as wnh\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "reload(ctf)\n",
    "reload(wnh)\n",
    "definition = \"Strumento che permette di ottenere immagini ingrandite di oggetti molto piccoli rivelando dettagli altrimenti invisibili.\"\n",
    "print (f\"Definizione: {definition}\")\n",
    "\n",
    "\n",
    "# Cercare synset candidati usando il sistema content-to-form (aumentare a 30 candidati)\n",
    "candidates_en = ctf.search_synset_from_definition(\n",
    "    definition,\n",
    "    lang='ita',\n",
    "    max_results=10,\n",
    "    DEBUG=0,\n",
    "    deep_search=6,\n",
    "    similarity_method=\"cosine\",\n",
    ")\n",
    "\n",
    "c=10\n",
    "\n",
    "print(f\"Top {c} synset candidati (Cosine Similarity):\\n\")\n",
    "for i, (synset, score) in enumerate(candidates_en[:c], 1):\n",
    "    print(f\"{i}. {synset.name()} (score: {score:.3f})\")\n",
    "    print(f\"   Definizione: {synset.definition()}\")\n",
    "    print(f\"   Lemmi: {', '.join([l.name() for l in synset.lemmas()][:5])}\")\n",
    "    if synset.hypernyms():\n",
    "        print(f\"   Iperonimo: {synset.hypernyms()[0].name()}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de88254",
   "metadata": {},
   "source": [
    "## Applicazione\n",
    "\n",
    "Procediamo ora ad applicare la ricerca onomasiologica a tutte le definizioni prodotte, e a valutare i risultati ottenuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d41a88f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del dataset long: (152, 2)\n",
      "Concetti nel dataset: ['Pantalone', 'Microscopio', 'Pericolo', 'Euristica']\n",
      "Definizioni per concetto:\n",
      "- Pantalone: 38\n",
      "- Microscopio: 38\n",
      "- Pericolo: 38\n",
      "- Euristica: 38\n",
      "\n",
      "Gold synset (se disponibile):\n",
      "- Pantalone: trouser.n.01\n",
      "- Microscopio: microscope.n.01\n",
      "- Pericolo: risk.n.02\n",
      "- Euristica: heuristic.n.01\n"
     ]
    }
   ],
   "source": [
    "# Caricare dataset definizioni (se non gia presente)\n",
    "if 'definitions_df' not in globals():\n",
    "    definitions_df = pd.read_csv(\"data/dataset_definizioni_Lab2.csv\", sep=';')\n",
    "\n",
    "# Trasformare il dataset wide in formato long (concetto, definizione)\n",
    "data_long = []\n",
    "concept_definitions = {}\n",
    "for concept in definitions_df.columns:\n",
    "    definitions = []\n",
    "    for definition in definitions_df[concept].dropna():\n",
    "        definition = str(definition).strip()\n",
    "        if definition:\n",
    "            data_long.append({\"concept\": concept, \"definition\": definition})\n",
    "            definitions.append(definition)\n",
    "    concept_definitions[concept] = definitions\n",
    "\n",
    "df = pd.DataFrame(data_long)\n",
    "\n",
    "print(f\"Shape del dataset long: {df.shape}\")\n",
    "print(f\"Concetti nel dataset: {list(concept_definitions.keys())}\")\n",
    "print(f\"Definizioni per concetto:\")\n",
    "for concept, defs in concept_definitions.items():\n",
    "    print(f\"- {concept}: {len(defs)}\")\n",
    "\n",
    "# Mappa concetto -> synset gold (fallback su mappature manuali)\n",
    "manual_gold_map = {\n",
    "    \"Pantalone\": [\"trouser.n.01\", \"pants.n.01\", \"pant.n.01\"],\n",
    "    \"Microscopio\": [\"microscope.n.01\"],\n",
    "    \"Pericolo\": [\"danger.n.01\", \"peril.n.01\"],\n",
    "    \"Euristica\": [\"heuristic.n.01\"],\n",
    "}\n",
    "\n",
    "def resolve_gold_synset(concept_name: str) -> Optional[str]:\n",
    "    \"\"\"Restituisce un synset gold per il concetto, se disponibile.\"\"\"\n",
    "    # Prova WordNet italiano\n",
    "    ita_synsets = wn.synsets(concept_name, lang='ita')\n",
    "    if ita_synsets:\n",
    "        return ita_synsets[0].name()\n",
    "    # Prova mappatura manuale\n",
    "    for syn_name in manual_gold_map.get(concept_name, []):\n",
    "        try:\n",
    "            wn.synset(syn_name)\n",
    "            return syn_name\n",
    "        except Exception:\n",
    "            continue\n",
    "    # Fallback: traduci il concetto e prova con WordNet inglese\n",
    "    translated = wnh.translate_tokens(concept_name, lang='ita', DEBUG=0)\n",
    "    for tok in translated:\n",
    "        syns = wn.synsets(tok, pos='n', lang='eng')\n",
    "        if syns:\n",
    "            return syns[0].name()\n",
    "    return None\n",
    "\n",
    "concept_to_synsets = {}\n",
    "for concept in concept_definitions.keys():\n",
    "    gold = resolve_gold_synset(concept)\n",
    "    concept_to_synsets[concept] = [gold] if gold else []\n",
    "\n",
    "print(\"\\nGold synset (se disponibile):\")\n",
    "for concept, syns in concept_to_synsets.items():\n",
    "    print(f\"- {concept}: {syns[0] if syns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricerca onomasiologica per tutte le definizioni con fallback\n",
    "def search_with_fallback(definition: str, max_results: int = 10) -> List[Tuple]:\n",
    "    \"\"\"Cerca synset con fallback da ITA -> ENG se necessario.\"\"\"\n",
    "    # Prima prova in italiano\n",
    "    candidates = ctf.search_synset_from_definition(\n",
    "        definition,\n",
    "        lang='ita',\n",
    "        max_results=10,\n",
    "        DEBUG=0,\n",
    "        deep_search=6,\n",
    "        similarity_method=\"cosine\",\n",
    "    )\n",
    "    if candidates:\n",
    "        return candidates\n",
    "    # Fallback: traduci i token e cerca in inglese\n",
    "    translated_tokens = wnh.translate_tokens(definition, lang='ita', DEBUG=0)\n",
    "    if not translated_tokens:\n",
    "        return []\n",
    "    candidate_synsets = []\n",
    "    seen = set()\n",
    "    for tok in translated_tokens:\n",
    "        for synset in wn.synsets(tok, lang='eng'):\n",
    "            if synset.name() not in seen:\n",
    "                seen.add(synset.name())\n",
    "                candidate_synsets.append(synset.name())\n",
    "    if not candidate_synsets:\n",
    "        return []\n",
    "    ranked = ctf.rank_synsets_by_similarity(\n",
    "        translated_tokens,\n",
    "        candidate_synsets,\n",
    "        similarity_method=\"jaccard\",\n",
    "        lang=\"eng\",\n",
    "        DEBUG=0,\n",
    "    )\n",
    "    return ranked[:max_results]\n",
    "\n",
    "results_by_concept = {}\n",
    "for concept, definitions in concept_definitions.items():\n",
    "    concept_results = []\n",
    "    for definition in definitions:\n",
    "        candidates = search_with_fallback(definition, max_results=10)\n",
    "        concept_results.append({\n",
    "            \"definition\": definition,\n",
    "            \"candidates\": candidates,\n",
    "        })\n",
    "    results_by_concept[concept] = concept_results\n",
    "\n",
    "print(\"Ricerca completata.\")\n",
    "for concept, items in results_by_concept.items():\n",
    "    print(f\"- {concept}: {len(items)} definizioni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabella riassuntiva per concetto\n",
    "summary_rows = []\n",
    "for concept, items in results_by_concept.items():\n",
    "    gold_list = concept_to_synsets.get(concept, [])\n",
    "    gold_synset = None\n",
    "    if gold_list:\n",
    "        try:\n",
    "            gold_synset = wn.synset(gold_list[0])\n",
    "        except Exception:\n",
    "            gold_synset = None\n",
    "\n",
    "    perfect = 0\n",
    "    top10 = 0\n",
    "    miss = 0\n",
    "    for item in items:\n",
    "        preds = [syn for syn, _ in item[\"candidates\"]]\n",
    "        rank = evaluation.find_rank_of_correct(preds, gold_synset)\n",
    "        if rank is None:\n",
    "            miss += 1\n",
    "        elif rank == 1:\n",
    "            perfect += 1\n",
    "        elif rank <= 10:\n",
    "            top10 += 1\n",
    "        else:\n",
    "            miss += 1\n",
    "    summary_rows.append({\n",
    "        \"concept\": concept,\n",
    "        \"perfect_top1\": perfect,\n",
    "        \"success_top10\": top10,\n",
    "        \"failures\": miss,\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(by=\"concept\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico: performance per concetto\n",
    "if 'summary_df' in globals() and not summary_df.empty:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    x = np.arange(len(summary_df))\n",
    "    width = 0.25\n",
    "\n",
    "    plt.bar(x - width, summary_df['perfect_top1'], width, label='Top 1')\n",
    "    plt.bar(x, summary_df['success_top10'], width, label='Top 10')\n",
    "    plt.bar(x + width, summary_df['failures'], width, label='Fallimenti')\n",
    "\n",
    "    plt.xticks(x, summary_df['concept'], rotation=30, ha='right')\n",
    "    plt.ylabel('Numero definizioni')\n",
    "    plt.title('Risultati content-to-form per concetto')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"summary_df non disponibile o vuoto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1bf62",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
