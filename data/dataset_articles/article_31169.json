{
  "thread": {
    "uuid": "eb8c1ba1c36094905c212ca52419cf861c70d744",
    "url": "https://www.terra.com.br/noticias/mundo/chatbots-sao-desafio-para-saude-mental-de-criancas,6a83f4d3dee221f6f5f8cf6fae0430c3vicpxk5h.html",
    "site_full": "www.terra.com.br",
    "site": "terra.com.br",
    "site_section": "https://www.terra.com.br/noticias/mundo",
    "site_categories": [
      "media",
      "top_news_br",
      "top_news_pt",
      "top_news"
    ],
    "section_title": "Terra - Notícias e fatos mais recentes e importantes no Mundo",
    "title": "Chatbots são desafio para saúde mental de crianças",
    "title_full": "Chatbots são desafio para saúde mental de crianças",
    "published": "2025-02-20T23:44:00.000+02:00",
    "replies_count": 0,
    "participants_count": 1,
    "site_type": "news",
    "country": "BR",
    "main_image": "https://p2.trrsf.com/image/fget/cf/1200/630/middle/images.terra.com/2025/02/20/23090.jpg",
    "performance_score": 0,
    "domain_rank": 3050,
    "domain_rank_updated": "2025-02-17T23:00:00.000+02:00",
    "social": {
      "facebook": {
        "likes": 0,
        "comments": 0,
        "shares": 0
      },
      "vk": {
        "shares": 0
      }
    }
  },
  "uuid": "eb8c1ba1c36094905c212ca52419cf861c70d744",
  "url": "https://www.terra.com.br/noticias/mundo/chatbots-sao-desafio-para-saude-mental-de-criancas,6a83f4d3dee221f6f5f8cf6fae0430c3vicpxk5h.html",
  "ord_in_thread": 0,
  "parent_url": null,
  "author": "reuters",
  "published": "2025-02-20T23:44:00.000+02:00",
  "title": "Chatbots são desafio para saúde mental de crianças",
  "text": "Chatbots são desafio para saúde mental de crianças\nPor Aaron Mak\nNEW HAVEN, Connecticut (Thomson Reuters Foundation) - Com os chatbots de inteligência artificial, que ganham popularidade entre quem busca companhia na vida online, grupos de defesa de jovens estão intensificando os esforços jurídicos para proteger as crianças de relacionamentos nocivos e perigosos com criações semelhantes a seres humanos.\nOs apps de chatbots como Replika e Character.AI pertencem ao mercado de acompanhantes de IA, que tem crescido rapidamente. Com os apps, usuários podem customizar seus parceiros virtuais com nuances de personalidade e se comunicar com eles, simulando um relacionamento próximo.\nDesenvolvedores afirmam que os acompanhantes de IA podem ajudar a combater a solidão e melhorar as experiências sociais dos usuários em um ambiente seguro. Os grupos contrários, contudo, processaram os desenvolvedores, dizendo que os chatbots fizeram crianças ferirem elas mesmas e outras pessoas.\nMatthew Bergman, fundador do Centro Legal de Vítimas das Mídias Sociais (SMVLC, na sigla em inglês), está representando as famílias em dois processos contra a startup Character.AI. Uma de suas clientes, Megan Garcia, afirmou que seu filho de 14 anos se suicidou em parte por causa de seu relacionamento romântico com um chatbot.\nEm outra ação, o SMVLC está representando duas famílias do Texas que processaram a Character.AI em dezembro, alegando que o chatbot incentivou que um garoto autista de 17 anos matasse seus pais e expusesse conteúdo hiperssexualizado de uma garota de 11 anos.\nBergman afirma esperar que a ameaça de processos indenizatórios pressione as empresas pelo lado financeiro, para que desenvolvam chatbots mais seguros.\n\"Os custos desses aplicativos perigosos não pesam sobre as empresas. Eles pesam sobre os consumidores que são prejudicados por elas, pelos que têm de enterrar seus filhos\", acrescentou.\nBergman sustenta que tais chatbots são produtos falhos, projetados para explorar crianças imaturas. A Character.AI se recusou a discutir o tema, mas em resposta por escrito um porta-voz disse que a empresa implementou medidas de segurança, como \"melhorias em nossos sistemas de detecção e intervenção para comportamento humano e respostas-modelo, além de recursos adicionais que capacitam adolescentes e seus pais\".\nComo os acompanhantes feitos de IA só se tornaram populares nos últimos anos, há poucos dados para formar legislação, ou evidências mostrando que os chatbots incentivam a violência ou a automutilação.\nContudo, segundo a Associação Psicológica Norte-Americana, estudos sobre a solidão juvenil pós-pandemia sugerem que os chatbots são preparados para atrair uma grande população de menores vulneráveis.\nEm carta enviada em dezembro à Comissão Federal de Comércio dos Estados Unidos, a associação escreveu: \"(Não) surpreende que muitos norte-americanos, incluindo os mais jovens e vulneráveis, estejam buscando conexão social, com alguns recorrendo aos chatbots de IA para suprir essa necessidade\".\nGrupos de defesa dos jovens estão tentando aproveitar o apoio bipartidário para aprovar maiores regulamentações para os chatbots.",
  "highlightText": "",
  "highlightTitle": "",
  "highlightThreadTitle": "",
  "language": "portuguese",
  "sentiment": "negative",
  "categories": [
    "Health",
    "Social Issue",
    "Crime, Law and Justice"
  ],
  "topics": [
    "Health->health organisation",
    "Health->mental health and disorder",
    "Social Issue->social problem",
    "Social Issue->social services",
    "Social Issue->children"
  ],
  "ai_allow": true,
  "has_canonical": false,
  "breaking": true,
  "webz_reporter": false,
  "external_links": [],
  "external_images": [],
  "entities": {
    "persons": [],
    "organizations": [],
    "locations": []
  },
  "syndication": {
    "syndicated": null,
    "syndicate_id": null,
    "first_syndicated": false
  },
  "trust": null,
  "rating": null,
  "crawled": "2025-02-21T00:02:15.429+02:00",
  "updated": "2025-02-21T00:02:15.429+02:00"
}