{
  "thread": {
    "uuid": "36d86b92ff75fb2d5b84b5f7c5c855a2c0f3cd12",
    "url": "https://epocanegocios.globo.com/colunas/iagora/coluna/2023/12/a-assertiva-e-contundente-mensagem-do-papa-francisco-sobre-ia.ghtml",
    "site_full": "epocanegocios.globo.com",
    "site": "globo.com",
    "site_section": "https://epocanegocios.globo.com/rss/epocanegocios",
    "site_categories": [
      "tennis",
      "sports"
    ],
    "section_title": "epocanegocios",
    "title": "A assertiva e contundente mensagem do Papa Francisco sobre IA | IAgora? | Época NEGÓCIOS",
    "title_full": "A assertiva e contundente mensagem do Papa Francisco sobre IA | IAgora? | Época NEGÓCIOS",
    "published": "2023-12-29T16:33:00.000+02:00",
    "replies_count": 0,
    "participants_count": 1,
    "site_type": "news",
    "country": "BR",
    "main_image": "https://s2-epocanegocios.glbimg.com/IVuA1IMPTRXifWgAnHNPASJH6Hs=/1200x/smart/filters:cover():strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "performance_score": 0,
    "domain_rank": 745,
    "domain_rank_updated": "2023-12-26T12:06:20.000+02:00",
    "reach": null,
    "social": {
      "facebook": {
        "likes": 29,
        "comments": 42,
        "shares": 12
      },
      "gplus": {
        "shares": 0
      },
      "pinterest": {
        "shares": 0
      },
      "linkedin": {
        "shares": 0
      },
      "stumbledupon": {
        "shares": 0
      },
      "vk": {
        "shares": 0
      }
    }
  },
  "uuid": "36d86b92ff75fb2d5b84b5f7c5c855a2c0f3cd12",
  "url": "https://epocanegocios.globo.com/colunas/iagora/coluna/2023/12/a-assertiva-e-contundente-mensagem-do-papa-francisco-sobre-ia.ghtml",
  "ord_in_thread": 0,
  "parent_url": null,
  "author": "globo.com",
  "published": "2023-12-29T16:33:00.000+02:00",
  "title": "A assertiva e contundente mensagem do Papa Francisco sobre IA | IAgora? | Época NEGÓCIOS",
  "text": "Papa Francisco (Foto: Franco Origlia/Getty Images) — Foto: Epoca Negocios Na mensagem “‘Inteligência Artificial e Paz” , escrita para a 57ª Conferência do Dia Mundial da Paz, a ser realizada em 1º de janeiro de 2024, o Papa Francisco enfatiza a necessidade de garantir que os sistemas de inteligência artificial (IA) não substituam os valores humanos, alertando sobre o risco de “cair na espiral de uma ditadura tecnológica”. Na mensagem, o Papa alerta para os numerosos riscos associados ao desenvolvimento da IA e clama pelo estabelecimento de um tratado internacional vinculativo que regule a tecnologia, particularmente as armas autônomas, garantindo o direcionamento da investigação tecnológica para a “busca da paz e do bem comum”.\nEstrutura de governança da OpenAI: conflito de propósitos e de culturas A polêmica do Prêmio Jabuti: o uso de IA generativa desqualifica a obra artística?\nEmbora as “máquinas ‘inteligentes’ possam executar as tarefas que lhes são atribuídas com eficiência cada vez maior, a inteligência artificial é meramente fragmentária no sentido de que só pode imitar ou reproduzir certas funções da inteligência humana. A capacidade humana única de julgamento moral e tomada de decisão ética é mais do que uma coleção complexa de algoritmos, e essa capacidade não pode ser reduzida à programação de uma máquina, que por mais 'inteligente' que seja, continua a ser uma máquina”, pondera o Papa Francisco, concluindo: “Precisamos lembrar que a pesquisa científica e as inovações tecnológicas não são desencarnadas e ‘neutras’, mas estão sujeitas a influências culturais. Sendo atividades plenamente humanas, os rumos que tomam refletem escolhas condicionadas por valores pessoais, sociais e culturais de qualquer época”.\nPara o Papa, os governos e as organizações multilaterais devem desempenhar um papel decisivo no estabelecimento de acordos que previnam não apenas práticas prejudiciais, mas também incentivem melhores práticas e abordagens criativas. “É minha oração no início do novo ano que o rápido desenvolvimento de formas de inteligência artificial não aumente os casos de desigualdade e injustiça tão presentes no mundo de hoje, mas ajude a pôr fim às guerras e aos conflitos e a aliviar muitas formas de sofrimento que afligem a nossa família humana”, defende o pontífice.\nA mensagem do Papa Francisco encerra com propriedade o ano de hype da inteligência artificial - segundo a Wikimedia Foundation, organização sem fins lucrativos por trás da enciclopédia online, em 2023 a Wikipédia em inglês teve mais de 84 bilhões de visualizações; o ChatGPT foi o campeão de popularidade, com 49.490.406 visualizações em todos os idiomas, e 78 milhões de visualizações de páginas de artigos.\nVeja a tradução da mensagem\n“No início do novo ano, tempo de graça que o Senhor concede a cada um de nós, gostaria de me dirigir ao Povo de Deus, às diversas nações, aos Chefes de Estado e de Governo, aos líderes das diversas religiões e da sociedade civil, e todos os homens e mulheres do nosso tempo, para apresentar os meus fervorosos bons votos de paz. […] O progresso na ciência e na tecnologia, na medida em que contribui para uma maior ordem na sociedade humana e para uma maior comunhão e liberdade fraterna, conduz assim à melhoria da humanidade e à transformação do mundo. Com razão, regozijamo-nos e damos graças pelas impressionantes conquistas da ciência e da tecnologia, cujos resultados possibilitaram remediar inúmeros males que outrora atormentavam a vida humana e causavam grandes sofrimentos. Ao mesmo tempo, os avanços tecnocientíficos, ao permitirem exercer um controle sobre a realidade até agora sem precedentes, estão a colocar nas mãos humanas um vasto leque de opções, incluindo algumas que podem representar um risco para a nossa sobrevivência e pôr em perigo a nossa casa comum. Os avanços notáveis nas novas tecnologias da informação, especialmente na esfera digital, oferecem, portanto, oportunidades estimulantes e graves riscos, com sérias implicações para a busca da justiça e da harmonia entre os povos. Algumas perguntas urgentes precisam ser feitas, tais como quais serão as consequências, a médio e longo prazo, destas novas tecnologias digitais? E que impacto terão nas vidas individuais e nas sociedades, na estabilidade e na paz internacionais?\nSobre o futuro da inteligência artificial, entre a promessa e o risco: o progresso na tecnologia da informação e o desenvolvimento das tecnologias digitais nas últimas décadas já começaram a efetuar profundas transformações na sociedade global e nas suas diversas dinâmicas. As novas tecnologias digitais estão ainda hoje a mudar a face das comunicações, da administração pública, da educação, do consumo, das interações pessoais e de inúmeros outros aspetos da nossa vida cotidiana. Além disso, a partir das ‘pegadas digitais' espalhadas pela internet, as tecnologias que empregam uma variedade de algoritmos podem extrair dados que lhes permitem controlar hábitos mentais e relacionais para fins comerciais ou políticos, muitas vezes sem o nosso conhecimento, limitando assim o nosso exercício consciente de liberdade de escolha. Num espaço como a Web, marcado pela sobrecarga de informações, podem estruturar o fluxo de dados segundo critérios de seleção nem sempre percebidos pelo usuário. Precisamos lembrar que a pesquisa científica e as inovações tecnológicas não são desencarnadas e ‘neutras’, mas estão sujeitas a influências culturais. Sendo atividades plenamente humanas, os rumos que tomam refletem escolhas condicionadas por valores pessoais, sociais e culturais de qualquer época. O mesmo se deve dizer dos resultados que produzem: precisamente como fruto de formas especificamente humanas de abordar o mundo que nos rodeia, estes últimos têm sempre uma dimensão ética, intimamente ligada às decisões tomadas por quem desenha a sua experimentação e orienta a sua produção para objetivos particulares. Este também é o caso das formas de inteligência artificial. Até o momento, não existe uma definição única de inteligência artificial no mundo da ciência e da tecnologia. O próprio termo, que já entrou na linguagem cotidiana, abrange uma variedade de ciências, teorias e técnicas destinadas a fazer com que as máquinas reproduzam ou imitem no seu funcionamento as capacidades cognitivas dos seres humanos. Falar no plural de ‘formas de inteligência’ pode ajudar a enfatizar acima de tudo o fosso intransponível entre tais sistemas, por mais surpreendentes e poderosos que sejam, e a pessoa humana: no final, eles são apenas ‘fragmentados', no sentido de que eles só podem imitar ou reproduzir certas funções da inteligência humana. A utilização do plural também revela o fato de que estes dispositivos diferem muito entre si e que devem ser sempre considerados como ‘sistemas sociotécnicos’. Pois o impacto de qualquer dispositivo de inteligência artificial – independentemente da sua tecnologia subjacente – depende não apenas da sua concepção técnica, mas também dos objetivos e interesses dos seus proprietários e criadores, e das situações em que serão utilizados. A inteligência artificial, então, deve ser entendida como uma galáxia de realidades diferentes. Não podemos presumir a priori que o seu desenvolvimento trará uma contribuição benéfica para o futuro da humanidade e para a paz entre os povos. Esse resultado positivo só será alcançado se nos mostrarmos capazes de agir de forma responsável e respeitar valores humanos fundamentais como ‘inclusão, transparência, segurança, equidade, privacidade e confiabilidade’. Também não é suficiente simplesmente presumir um compromisso por parte daqueles que concebem algoritmos e tecnologias digitais para agir de forma ética e responsável. É necessário reforçar ou, se necessário, criar órgãos encarregados de examinar as questões éticas que surgem neste domínio e de proteger os direitos daqueles que empregam formas de inteligência artificial ou são afetados por elas. A imensa expansão da tecnologia necessita, portanto, ser acompanhada por uma formação adequada para a responsabilidade pelo seu desenvolvimento futuro. A liberdade e a coexistência pacífica são ameaçadas sempre que os seres humanos cedem à tentação do egoísmo, do interesse próprio, do desejo de lucro e da sede de poder. Temos, portanto, o dever de alargar o nosso olhar e de orientar a investigação técnico-científica para a busca da paz e do bem comum, a serviço do desenvolvimento integral dos indivíduos e das comunidades. A dignidade inerente a cada ser humano e a fraternidade que nos une como membros de uma única família humana devem sustentar o desenvolvimento de novas tecnologias e servir como critérios indiscutíveis para avaliá-las antes de serem utilizadas, para que o progresso digital possa ocorrer com o devido respeito pela justiça e contribuir para a causa da paz. Os desenvolvimentos tecnológicos que não conduzem a uma melhoria da qualidade de vida de toda a humanidade, mas, pelo contrário, agravam as desigualdades e os conflitos, nunca poderão ser considerados um verdadeiro progresso. A inteligência artificial se tornará cada vez mais importante. Os desafios que coloca são técnicos, mas também antropológicos, educacionais, sociais e políticos. Promete, por exemplo, a libertação do trabalho penoso, uma produção mais eficiente, transportes mais fáceis e mercados mais preparados, bem como uma revolução nos processos de acumulação, organização e confirmação de dados. Precisamos estar conscientes das rápidas transformações que estão a ocorrer e de as gerir de forma a salvaguardar os direitos humanos fundamentais e a respeitar as instituições e as leis que promovem o desenvolvimento humano integral. A inteligência artificial deve servir ao nosso melhor potencial humano e às nossas mais elevadas aspirações, e não competir com elas.\nSobre a tecnologia do futuro, máquinas que ‘aprendem sozinhas’: em suas múltiplas formas, a inteligência artificial baseada em técnicas de aprendizagem automática, embora ainda nas suas fases pioneiras, já está a introduzir mudanças consideráveis no tecido das sociedades e a exercer uma influência profunda nas culturas, nos comportamentos sociais e na construção da paz. Desenvolvimentos como a aprendizagem automática ou a aprendizagem profunda levantam questões que transcendem os domínios da tecnologia e da engenharia e têm a ver com a compreensão mais profunda do significado da vida humana, a construção do conhecimento e a capacidade da mente de alcançar a verdade. A capacidade de certos dispositivos produzirem textos sintática e semanticamente coerentes, por exemplo, não é garantia de sua confiabilidade. Diz-se que ‘alucinam’, isto é, criam declarações que à primeira vista parecem plausíveis, mas são infundadas ou revelam preconceitos. Isto representa um problema grave quando a inteligência artificial é utilizada em campanhas de desinformação que espalham notícias falsas e levam a uma desconfiança crescente nos meios de comunicação. A privacidade, a propriedade de dados e a propriedade intelectual são outras áreas onde estas tecnologias geram graves riscos. A que podemos acrescentar outras consequências negativas do uso indevido dessas tecnologias, como a discriminação, a interferência nas eleições, a ascensão de uma sociedade de vigilância, a exclusão digital e a exacerbação de um individualismo cada vez mais desligado da sociedade. Todos estes fatores correm o risco de alimentar conflitos e dificultar a paz.\nSobre a sensação de limite no paradigma tecnocrático: nosso mundo é muito vasto, variado e complexo para ser totalmente conhecido e categorizado. A mente humana nunca poderá esgotar a sua riqueza, mesmo com a ajuda dos algoritmos mais avançados. Tais algoritmos não oferecem previsões garantidas do futuro, mas apenas aproximações estatísticas. Nem tudo pode ser previsto, nem tudo pode ser calculado; no final, ‘as realidades são maiores que as ideias’. Por mais prodigioso que seja o nosso poder de cálculo, sempre haverá um resíduo inacessível que escapa a qualquer tentativa de quantificação. Além disso, a vasta quantidade de dados analisados pelas inteligências artificiais não é, por si só, garantia de imparcialidade. Quando os algoritmos extrapolam informações, correm sempre o risco de distorção, replicando as injustiças e preconceitos dos ambientes onde se originam. Quanto mais rápidos e complexos eles se tornam, mais difícil é entender por que produziram um determinado resultado. Máquinas ‘inteligentes’ poderão executar as tarefas que lhes são atribuídas com eficiência cada vez maior, mas o propósito e o significado das suas operações continuarão a ser determinados ou possibilitados por seres humanos possuidores do seu próprio universo de valores. Existe o risco de que os critérios subjacentes a certas decisões se tornem menos claros, a responsabilidade por essas decisões seja ocultada e os produtores possam fugir à sua obrigação de agir em benefício da comunidade. Em certo sentido, isto é favorecido pelo sistema tecnocrático, que alia a economia à tecnologia e privilegia o critério da eficiência, tendendo a ignorar tudo o que não esteja relacionado com os seus interesses imediatos. Isto deverá levar-nos a refletir sobre algo frequentemente esquecido na nossa atual mentalidade tecnocrática e orientada para a eficiência, por ser decisivo para o desenvolvimento pessoal e social: o ‘senso de limite’. Os seres humanos são, por definição, mortais; ao propor a superação de todos os limites através da tecnologia, num desejo obsessivo de controlar tudo, corremos o risco de perder o controle sobre nós mesmos; na busca por uma liberdade absoluta, corremos o risco de cair na espiral de uma ‘ditadura tecnológica’. Reconhecer e aceitar nossos limites como criaturas é condição indispensável para alcançar, ou melhor, acolher a realização como dádiva. No contexto ideológico de um paradigma tecnocrático inspirado por uma presunção prometeica de auto-suficiência, as desigualdades poderão crescer desproporcionalmente, o conhecimento e a riqueza acumular-se-ão nas mãos de poucos e surgirão graves riscos para as sociedades democráticas e para a coexistência pacífica.\nSobre questões urgentes para a ética: no futuro, a confiabilidade de um requerente de uma hipoteca, a aptidão de um indivíduo para um emprego, a possibilidade de reincidência por parte de uma pessoa condenada ou o direito de receber asilo político ou assistência social poderão ser determinados por sistemas de inteligência artificial. Os diferentes níveis de mediação que esses sistemas introduzem estão particularmente expostos a formas de preconceito e discriminação: os erros sistêmicos podem facilmente multiplicar-se, produzindo não só injustiças em casos individuais, mas também, devido ao efeito dominó, formas reais de desigualdade social. Por vezes, igualmente, formas de inteligência artificial parecem capazes de influenciar as decisões dos indivíduos, operando através de opções pré-determinadas associadas a estímulos e dissuasões, ou operando através de um sistema de regulação das escolhas das pessoas com base no design da informação. Estas formas de manipulação ou controle social requerem atenção e supervisão cuidadosas e implicam uma responsabilidade legal clara por parte dos seus produtores, dos seus implementadores e das autoridades governamentais. A confiança em processos automáticos que categorizam os indivíduos, por exemplo, através do uso generalizado de vigilância ou da adoção de sistemas de crédito social, poderia igualmente ter repercussões profundas no tecido social, ao estabelecer uma classificação entre os cidadãos. Estes processos artificiais de categorização podem também conduzir a conflitos de poder, uma vez que dizem respeito não apenas a utilizadores virtuais, mas também a pessoas reais. O respeito fundamental pela dignidade humana exige que recusemos permitir que a singularidade da pessoa seja identificada por um conjunto de dados. Não se deve permitir que os algoritmos determinem a forma como entendemos os direitos humanos, que deixem de lado os valores humanos essenciais da compaixão, da misericórdia e do perdão, ou que eliminem a possibilidade de um indivíduo mudar e deixar o seu passado para trás. Também não podemos deixar de considerar, nesse contexto, o impacto das novas tecnologias no local de trabalho. Empregos que antes eram domínio exclusivo do trabalho humano estão sendo rapidamente assumidos por aplicações industriais de inteligência artificial. Também aqui existe o risco substancial de benefícios desproporcionais para poucos, ao preço do empobrecimento de muitos. O respeito pela dignidade dos trabalhadores e a importância do emprego para o bem-estar econômico dos indivíduos, famílias e sociedades, para a segurança no emprego e salários justos, devem ser uma alta prioridade para a comunidade internacional à medida que estas formas de tecnologia penetram mais profundamente em nossos locais de trabalho.\nSobre transformar espadas em arados: nos dias de hoje, quando olhamos para o mundo que nos rodeia, não podemos escapar a sérias questões éticas relacionadas com o setor de armamento. A capacidade de conduzir operações militares através de sistemas de controle remoto levou a uma menor percepção da devastação causada por esses sistemas de armas e do peso da responsabilidade pela sua utilização, resultando numa abordagem ainda mais fria e distanciada da imensa tragédia da guerra. A investigação sobre tecnologias emergentes na área dos chamados sistemas de armas autônomas letais, incluindo a transformação da inteligência artificial em armas, é motivo de grave preocupação ética. Sistemas de armas autônomos nunca poderão ser sujeitos moralmente responsáveis. A capacidade humana única de julgamento moral e de tomada de decisões éticas é mais do que uma coleção complexa de algoritmos, e essa capacidade não pode ser reduzida à programação de uma máquina, que por mais ‘inteligente’ que seja, continua a ser uma máquina. Por esta razão, é imperativo garantir uma supervisão humana adequada, significativa e consistente dos sistemas de armas autônomos. Também não podemos ignorar a possibilidade de armas sofisticadas acabarem em mãos erradas, facilitando, por exemplo, ataques terroristas ou intervenções destinadas a desestabilizar as instituições de sistemas legítimos de governo. Numa palavra, o mundo não tem necessidade de novas tecnologias que contribuam para o desenvolvimento injusto do comércio de armas e, consequentemente, acabem por promover a loucura da guerra. Ao fazê-lo, não só a inteligência, mas o próprio coração humano correria o risco de se tornar cada vez mais ‘artificial’. As aplicações tecnológicas mais avançadas não devem ser utilizadas para facilitar a resolução violenta de conflitos, mas sim para preparar o caminho para a paz. Numa nota mais positiva, se a inteligência artificial fosse utilizada para promover o desenvolvimento humano integral, poderia introduzir inovações importantes na agricultura, na educação e na cultura, um melhor nível de vida para nações e povos inteiros, e o crescimento da fraternidade humana e da amizade social. No final, a forma como a utilizamos para incluir os nossos irmãos e irmãs mais pequeninos, os vulneráveis e os mais necessitados, será a verdadeira medida da nossa humanidade.\nSobre desafios para a educação: o desenvolvimento de uma tecnologia que respeite e sirva a dignidade humana tem ramificações claras para as nossas instituições educativas e para o mundo da cultura. Ao multiplicar as possibilidades de comunicação, as tecnologias digitais permitiram nos encontrar de novas formas. No entanto, continua a ser necessária uma reflexão sustentada sobre os tipos de relações para as quais nos estão a conduzir. Os nossos jovens crescem em ambientes culturais impregnados de tecnologia, e isso não pode deixar de desafiar os nossos métodos de ensino, educação e formação. A educação, ao utilizar sistemas de inteligência artificial, deve visar acima de tudo a promoção do pensamento crítico. Os utilizadores de todas as idades, mas especialmente os jovens, precisam desenvolver uma abordagem criteriosa à utilização de dados e conteúdos recolhidos na Web ou produzidos por sistemas de inteligência artificial. Escolas, universidades e sociedades científicas são desafiadas a ajudar estudantes e profissionais a compreender os aspectos sociais e éticos do desenvolvimento e da utilização da tecnologia. A formação na utilização dos novos meios de comunicação deve também ter em conta não só a desinformação, as notícias falsas, mas também o preocupante recrudescimento de certos medos ancestrais… que conseguiram esconder-se e espalhar-se por trás das novas tecnologias. Infelizmente, mais uma vez temos que combater a tentação de construir uma cultura de muros, de erguer muros… para evitar o encontro com outras culturas e outros povos, e o desenvolvimento de uma sociedade pacífica e convivência fraterna. Uma perspectiva autenticamente humana e o desejo de um futuro melhor para o nosso mundo indicam certamente a necessidade de um diálogo interdisciplinar que vise um desenvolvimento ético de algoritmos – uma ética algorítmica – em que os valores moldarão os rumos tomados pelas novas tecnologias. As considerações éticas também devem ser tidas em conta desde o início da investigação e continuar durante as fases de experimentação, concepção, produção, distribuição e comercialização. Esta é a abordagem da ética desde a concepção, e é aquela em que as instituições educativas e os decisores têm um papel essencial a desempenhar.\nSobre os desafios para o desenvolvimento do direito internacional: a escala global da inteligência artificial deixa claro que, juntamente com a responsabilidade dos Estados soberanos de regular a sua utilização internamente, as organizações internacionais podem desempenhar um papel decisivo na obtenção de acordos multilaterais e na coordenação da sua aplicação e execução. A este respeito, exorto a comunidade global de nações a trabalhar em conjunto, a fim de adotar um tratado internacional vinculativo que regule o desenvolvimento e a utilização da inteligência artificial nas suas muitas formas. O objetivo da regulamentação, naturalmente, não deve ser apenas a prevenção de práticas prejudiciais, mas também o incentivo às melhores práticas, estimulando abordagens novas e criativas e encorajando iniciativas individuais ou de grupo. Na busca por modelos normativos que possam fornecer orientação ética aos desenvolvedores de tecnologias digitais, é indispensável identificar os valores humanos que devem sustentar os esforços das sociedades para formular, adotar e fazer cumprir os tão necessários quadros regulatórios. O trabalho de elaboração de diretrizes éticas para a produção de formas de inteligência artificial dificilmente pode prescindir da consideração de questões mais profundas relativas ao significado da existência humana, à proteção dos direitos humanos fundamentais e à busca da justiça e da paz. Este processo de discernimento ético e jurídico pode constituir uma oportunidade preciosa para uma reflexão partilhada sobre o papel que a tecnologia deve desempenhar nas nossas vidas individuais e comunitárias, e como a sua utilização pode contribuir para a criação de um mundo mais equitativo e humano. Por essa razão, nos debates sobre a regulamentação da inteligência artificial, as vozes de todas as partes interessadas devem ser tidas em conta, incluindo os pobres, os impotentes e outros que muitas vezes não são ouvidos nos processos de tomada de decisão globais.\nEspero que a reflexão anterior encoraje os esforços para garantir que o progresso no desenvolvimento de formas de inteligência artificial sirva, em última análise, a causa da fraternidade humana e da paz. Não é responsabilidade de alguns, mas de toda a família humana. Porque a paz é fruto de relações que reconhecem e acolhem os outros na sua dignidade inalienável, e da cooperação e do compromisso na busca do desenvolvimento integral de todos os indivíduos e povos. É minha oração, no início do Ano Novo, que o rápido desenvolvimento de formas de inteligência artificial não aumente os casos de desigualdade e injustiça, tão presentes no mundo de hoje, mas ajude a pôr fim às guerras e aos conflitos e a aliviar muitas formas de sofrimento que afligem a nossa família humana. Que os crentes cristãos, os seguidores de diversas religiões e os homens e mulheres de boa vontade trabalhem juntos e em harmonia para aproveitar as oportunidades e enfrentar os desafios colocados pela revolução digital e assim transmitir às gerações futuras um mundo de mais solidariedade, justiça e paz.“\nFeliz ano novo!\nSiga a Epoca Negócios: Mais recente Próxima Regulamentação da IA na Europa: acordo tripartite provisório",
  "highlightText": "",
  "highlightTitle": "",
  "highlightThreadTitle": "",
  "language": "portuguese",
  "sentiment": "positive",
  "categories": [
    "Science and Technology",
    "Religion and Belief"
  ],
  "external_links": [
    "https://s2-epocanegocios.glbimg.com/6tZQ_9GRL9TwnBYb0FbTyQWc54s=/0x0:620x350/640x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "https://s2-epocanegocios.glbimg.com/_jiwOfvRqe3z2X6rKQkq0fGtA_w=/0x0:620x350/600x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "https://s2-epocanegocios.glbimg.com/4xipBKqCzPMEp3vIsALZ8FLjKpM=/0x0:620x350/1000x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "https://twitter.com/epocanegocios",
    "https://s2-epocanegocios.glbimg.com/4bfSTVrXIOk3FjxyDntNq1xtkIM=/0x0:620x350/984x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "https://www.linkedin.com/showcase/epocanegocios/",
    "https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
    "https://www.instagram.com/epocanegocios/",
    "https://www.youtube.com/c/%C3%89pocaNEG%C3%93CIOSRevista/featured",
    "https://www.facebook.com/epocanegocios/",
    "https://www.s2-epocanegocios.glbimg.com/_jiwOfvRqe3z2X6rKQkq0fGtA_w=/0x0:620x350/600x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "https://youtube.com/c/%C3%89pocaNEG%C3%93CIOSRevista/featured",
    "https://facebook.com/epocanegocios/",
    "https://www.s2-epocanegocios.glbimg.com/6tZQ_9GRL9TwnBYb0FbTyQWc54s=/0x0:620x350/640x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "https://www.s2-epocanegocios.glbimg.com/4bfSTVrXIOk3FjxyDntNq1xtkIM=/0x0:620x350/984x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "https://vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
    "https://linkedin.com/showcase/epocanegocios/",
    "https://www.twitter.com/epocanegocios",
    "https://www.instagram.com/epocanegocios",
    "https://www.facebook.com/epocanegocios",
    "https://www.linkedin.com/showcase/epocanegocios",
    "https://www.s2-epocanegocios.glbimg.com/4xipBKqCzPMEp3vIsALZ8FLjKpM=/0x0:620x350/1000x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_e536e40f1baf4c1a8bf1ed12d20577fd/internal_photos/bs/2022/J/J/6BML60S52EhOWlIy7nhg/2016-11-26-gettyimages-454298983.jpeg",
    "https://instagram.com/epocanegocios/"
  ],
  "external_images": [],
  "entities": {
    "persons": [],
    "organizations": [],
    "locations": []
  },
  "rating": null,
  "crawled": "2023-12-29T18:51:11.801+02:00",
  "updated": "2023-12-29T18:51:11.801+02:00"
}