{
  "thread": {
    "uuid": "930b2a533ced7ed9f65b787dbe52f8cb05782738",
    "url": "https://indianexpress.com/article/technology/tech-news-technology/how-deepfake-tech-is-weaponised-and-how-to-fight-back-9771402",
    "site_full": "indianexpress.com",
    "site": "indianexpress.com",
    "site_section": "https://indianexpress.com/puzzles-and-games",
    "site_categories": [
      "media",
      "top_news_in",
      "top_news_kw",
      "top_news_nz",
      "top_news_pk",
      "top_news_ae",
      "top_news_au",
      "top_news_za",
      "top_news_qa",
      "top_news_sg",
      "top_news_sa",
      "top_news_my",
      "top_news"
    ],
    "section_title": "Free Online Games: Play best Puzzle Games online from Sudoku to Crossword and more brain games daily for free | The Indian Express",
    "title": "Your photos aren't safe: How deepfake tech is being weaponised, and how to fight back",
    "title_full": "Your photos aren't safe: How deepfake tech is being weaponised, and how to fight back",
    "published": "2025-01-10T09:02:00.000+02:00",
    "replies_count": 0,
    "participants_count": 1,
    "site_type": "news",
    "country": "IN",
    "main_image": "https://images.indianexpress.com/2025/01/Safe-Side-2.jpg",
    "performance_score": 0,
    "domain_rank": 936,
    "domain_rank_updated": "2025-01-06T23:00:00.000+02:00",
    "social": {
      "facebook": {
        "likes": 0,
        "comments": 0,
        "shares": 0
      },
      "vk": {
        "shares": 0
      }
    }
  },
  "uuid": "930b2a533ced7ed9f65b787dbe52f8cb05782738",
  "url": "https://indianexpress.com/article/technology/tech-news-technology/how-deepfake-tech-is-weaponised-and-how-to-fight-back-9771402",
  "ord_in_thread": 0,
  "parent_url": null,
  "author": "Ankita Deshkar",
  "published": "2025-01-10T09:02:00.000+02:00",
  "title": "Your photos aren't safe: How deepfake tech is being weaponised, and how to fight back",
  "text": "In this weekâ€™s The Safe Side, we explore the rise of deepfake technology, its dangers, and the avenues available to victims to protect themselves against the violation of their privacy. Written by Ankita Deshkar Nagpur | Updated: January 10, 2025 15:02 IST 8 min read The growing threat of deepfake pornography. (Image: Abhishek Mitra/The Indian Express) The misuse of artificial intelligence continues to challenge ethical and legal boundaries, with one of its most alarming manifestations being deepfake pornography. To counter this growing threat, the US Senate recently passed the bipartisan â€˜Take It Downâ€™ Act, which criminalises the publication of non-consensual intimate imagery, including AI-generated deepfake content. The Bill, which mandates social media platforms and websites to remove such content within 48 hours of notification from victims, now moves to the House for consideration.\nIt is important to understand the technology behind deepfake pornography, its rise, dangers, how individuals can protect themselves, and what to do if photos or videos are being misused.\nTo get insights about the issue, we spoke with Abhivardhan, chairperson and managing trustee, Indian Society of Artificial Intelligence and Law, and Lohit Matani, Nagpurâ€™s deputy commissioner of police (cyber).\nAdvertisement The growing threat of deepfake pornography In 2024, deepfakes took centre stage in India following morphed images of Bollywood celebrities Rashmika Mandanna, Alia Bhatt , and Katrina Kaif spread like wildfire on social media. However, deepfakes are not limited to celebrities, the technology has been used increasingly to target regular people, making deepfake pornography a widespread concern.\nAccording to social media analytics firm Twicsy, 84 per cent of social media influencers have fallen victim to deepfake pornography. What began with hyper-realistic AI-generated celebrity images has now transitioned into scams and blackmail targeting ordinary people.\nAlso Read | Love, lies, and loss: How scammers on dating apps lure lonely hearts Take the case of Sanket (name changed). Early last year, he clicked on a seemingly harmless advertisement on a social media platform. What followed was a nightmareâ€”scammers with access to his public pictures began blackmailing him with deepfake intimate images, threatening to distribute them unless he paid up.\n(Illustration: Abhishek Mitra/The Indian Express) Sanket initially ignored the threats, turning off his phone to avoid incessant WhatsApp calls. But the harassment escalated when fake Facebook profiles began sharing doctored images of him in the comments section of his posts. He deleted his Facebook profile and changed his number. Fearing judgment and distrust from law enforcement, Sanket chose not to report the incident to the cybercrime cell. â€œThey would have found faults in my social media usage, would have judged me for clicking on an inappropriate advertisement, and I believe nothing would have changed,â€ he told indianexpress.com .\nAdvertisement With better awareness, Sanket could have averted the emotional and social toll of such a traumatic experience.\nHow are deepfakes made? Creating deepfake pornography has become alarmingly easy, with more than a hundred â€œnudifyâ€ websites, software and applications available online. These tools allow even users with minimal technical skills to create deepfakes. A simple search will lead users to these websites.\nWhile â€œrulesâ€ on such websites say only those above 18 years of age are allowed, there is no proof or verification required, much like on porn sites, and even though such websites warn users not to use othersâ€™ images without their permission, it is obvious users are not going to use the tool to create their own pornographic images.\nAccording to Abhivardhan, cases of deepfakes in India have grown at an alarming paceâ€”not just in political campaigns but also in non-political contexts. â€œAccording to a report, deepfake online content increased by 900 per cent between 2019 and 2020 globally, and some researchers predict that up to 90 per cent of online content could be made synthetically by 2026. More recent analysis shows that Indian social media users are frequently exposed to AI-altered media,â€ he said.\nAdvertisement (Illustration: Abhishek Mitra/ The Indian Express ) Modern AI deepfakes are powered by Generative Adversarial Networks (GANs), which uses two machine-learning models: a â€œgeneratorâ€ to create synthetic media and a â€œdiscriminatorâ€ to detect if itâ€™s fake. Through repeated attempts, the generator refines its output until the visual or audio content is convincingly realistic. The continuous feedback loop between the generator and discriminator polishes the output until it is often indistinguishable from genuine footage, rendering it highly deceptive making these deepfakes very convincing. Advanced AI can capture minute detailsâ€”facial expressions, lighting nuances, voice tones, and more.\nIndiaâ€™s legal framework for deepfakes â€œAt present, India lacks a comprehensive legal framework specifically tailored to AI-generated content or deepfakes. AI platforms generally operate in a grey areaâ€”so long as they adhere to Indiaâ€™s Information Technology (IT) Act, 2000, and avoid hosting or distributing explicit illegal content, they may remain technically within legal limits. However, the law is still evolving,â€ Abhivardhan said.\nWhile the Bharatiya Nyaya Sanhita (BNS) 2023 includes provisions for defamation, fraud, identity theft, deepfakes or non-consensual AI-generated images and videos are not explicitly addressed. Same is the case with the IT Act, 2000.\nRecent advisories from the Ministry of Electronics and Information Technology have faced criticism for being vague and non-binding. Civil remedies under privacy and defamation laws also remain limited in scope.\nWhat should victims do? Preserve evidence: Capture screenshots, note URLs and timestamps of the manipulated content.\nAdvertisement Report to authorities: Capture screenshots, note URLs and timestamps of the manipulated content. File a complaint with the cybercrime cell via the Ministry of Home Affairs portal or local police station. Sections 66E (image privacy) of the IT Act or provisions of the BNS can be invoked.\nRequest platform takedowns: Most social media platforms have policies against non-consensual intimate images or manipulated content. Victims can file a takedown request with evidence.\nSeek legal help: A legal notice or cease-and-desist letter might be needed if the perpetrator or platform is unresponsive.\nNGOs and legal aid programmes: While India does not have a specific deepfake support organisation, certain digital rights groups, cyber law clinics, and pro bono legal initiatives may help navigate the process.\nAdvertisement Also Read | You are one click away from losing everything: The real danger of KYC scams According to Matani, â€œThe primary motive when a victim files a complaint regarding morphed intimate images is to take down the image from the platform where it has been uploaded or shared. The steps are to identify the account, deleting the media and identifying and nabbing the accused.â€\nIn cases involving sharing of such manipulated data on WhatsApp, â€œit becomes important to delete the images from the devices of the peopleâ€, said Matani. â€œIf the pictures are shared on WhatsApp groups, the admins are treated as accused in the case.\nThe accused are booked under the combination of sections from Information Technology Act, 2000 and the Bharatiya Nyay Sanhita, 2023. In cases of child pornography, the accused are booked under relevant sections of the Protection of Children from Sexual Offences Act (POCSO),â€ he said.\nPreventive measures Abhivardhan listed some preventive measures for social media users:\nAdvertisement ðŸ“ŒRestrict privacy settings: Limit who can view or download your content.\nðŸ“ŒAvoid sharing sensitive data: Remove geotags, personal identifiers, or any data that can be used to create convincing forgeries.\nðŸ“ŒTwo-factor authentication: Enable it to reduce account hacking risks.\nðŸ“ŒUse watermarking: Subtle watermarking of personal images can deter misuse. This may not be foolproof, it adds a barrier.\nðŸ“ŒBe vigilant: Regularly review tagged photos or unknown friend requests to catch unauthorised usage\nAdvertisement The way forward Deepfake technology poses unique challenges to privacy and security. Beyond its misuse in pornography, it enables sophisticated fraud, such as voice cloning for identity theft.\nAbhivardhan underscores the shared responsibility of governments, tech platforms, and citizens to address this issue. While AI-driven innovations hold promise, their misuse must be curtailed to protect personal rights and maintain public trust in digital spaces.\nDiscover the Benefits of Our Subscription! Stay informed with access to our award-winning journalism.\nAvoid misinformation with trusted, accurate reporting.\nMake smarter decisions with insights that matter.\nChoose your subscription package Recommended All-Access Digital + E-paper subscription so that you donâ€™t miss anything. Rs.1299/year BUY NOW Digital-Only Get unlimited access to all our journalism online (minus epaper). Rs.1199/year BUY NOW Â© IE Online Media Services Pvt Ltd Tags: artificial intelligence Latest Comment Post Comment Read Comments Advertisement Los Angeles fires: Whatâ€™s hampering firefighting efforts? World 2 hr ago The wildfires in Los Angeles, California have caused immense damage, resulting in seven fatalities, destruction of land and property, and evacuation of over 180,000 people. The fires, fueled by dry winds, are among the city's largest and continue to spread. Poor infrastructure and challenges with evacuation plans have hindered firefighting efforts.\nView all shorts More Tech Technology DailyObjects Loop and Noise Power Series review: Indian accessories with global ambitions Technology What is Watch Duty, the free app helping users track the wildfires in Los Angeles? Technology Physicists spot 44 stars no one knew existed thanks to 'cosmic hall of mirrors' effect Technology These Sennheiser earplugs help you take on loud noises Advertisement Photos CES 2025: A quick look at some of the most interesting gadgets announced this year Earth, space, and beyond: 12 new breathtaking images shared by NASA Lunar Eclipse 2022 images: Pictures of the last total lunar eclipse for next three years Photos: NASA and SpaceXâ€™s historic Crew-5 launch to International Space Station Atmanirbharta on lips, PM Modi launches 5G services in India Top Stories Pannun assassination plot case All our funds were spent on fighting case in Czech Republic: Nikhil Gupta from US jail Supreme Court halts action on well near Sambhal Shahi Jama Masjid, orders status quo Entertainment Game Changer review: A riveting Ram Charan anchors a middling Shankar showreel Entertainment Black Warrant review: Insider account of Tihar Jail is gritty, as real as possible Trending Britannia's new ad campaign turns billboards into eco-friendly art; gets the Internetâ€™s approval: â€˜Can we call it a pedh partnership?â€™ Trending Leopard lands a 'job' at Infosys: Wild visitor sparks memes on work culture Sports Is it time for India to look beyond Ravindra Jadeja in One-day International cricket? Sports Will selectors give Yashasvi maiden ODI call-up? Will Surya find a return route? Is Jadejaâ€™s time up? Opinion India-Taliban talks -- realism in Acting West Tirupati temple stampede: what is the Vaikuntha Ekadasi festival, what went wrong Lifestyle Transform your fitness routine with the 6-6-6 walking rule Technology DailyObjects Loop and Noise Power Series review: Indian accessories with global ambitions\nMust Read Sports Is it time for India to look beyond Ravindra Jadeja in One-day International cricket? Sports Will selectors give Yashasvi maiden ODI call-up? Will Surya find a return route? Is Jadejaâ€™s time up? Sports Malaysia Open badminton: Satwiksairaj Rankireddy-Chirag Shetty enter last 8 as they continue to chart way back from Olympics disappointment Technology DailyObjects Loop and Noise Power Series review: Indian accessories with global ambitions Technology What is Watch Duty, the free app helping users track the wildfires in Los Angeles? Technology Physicists spot 44 stars no one knew existed thanks to 'cosmic hall of mirrors' effect Lifestyle Transform your fitness routine with the 6-6-6 walking rule Advertisement Jan 10: Latest News 01 After drift setback, ISROâ€™s SpaDex mission ready for another docking attempt today 02 Everton sack manager Sean Dyche hours before FA Cup tie 03 Torres ponzi scheme fraud: EOW searches 6 places, seizes Rs 3 crore cash, names five more suspects 04 Malaysia Open badminton: Satwiksairaj Rankireddy-Chirag Shetty enter last 8 as they continue to chart way back from Olympics disappointment 05 Amid call for leadership change in NCP(SP), Patil tells detractors to show their report card Advertisement Link Subscription Subscribe Sign In e-paper Premium India Elections 2024 Bollywood Opinion Political Pulse Explained Science Cricket Sports World Business Entertainment Jobs Health Lifestyle Technology Education Movie Review Eye Trending Cities Newsletters WebSeries Photos Videos Audio Web Stories Trending Human Metapneumovirus Mini Crossword Premium Express Shorts ðŸŽ™ï¸ Podcast Health & Wellness close Edition India International .(Open in new tab) Subscribe Sign In e-paper Premium India Elections 2024 Bollywood Opinion Political Pulse Explained Science Cricket Sports World Business Entertainment Jobs Health Lifestyle Technology Education Movie Review Eye Trending Cities Newsletters WebSeries Photos Videos Audio Web Stories",
  "highlightText": "",
  "highlightTitle": "",
  "highlightThreadTitle": "",
  "language": "english",
  "sentiment": "negative",
  "categories": [
    "Science and Technology",
    "Social Issue",
    "Human Interest"
  ],
  "topics": [
    "Science and Technology->scientific research",
    "Science and Technology->social sciences",
    "Science and Technology->technology and engineering",
    "Social Issue->social problem",
    "Social Issue->discrimination"
  ],
  "ai_allow": true,
  "has_canonical": false,
  "breaking": null,
  "webz_reporter": false,
  "external_links": [],
  "external_images": [],
  "entities": {
    "persons": [],
    "organizations": [
      {
        "name": "US Senate",
        "sentiment": "none"
      }
    ],
    "locations": []
  },
  "syndication": {
    "syndicated": false,
    "syndicate_id": null,
    "first_syndicated": false
  },
  "rating": null,
  "crawled": "2025-01-10T11:53:40.140+02:00",
  "updated": "2025-01-10T12:25:11.096+02:00"
}