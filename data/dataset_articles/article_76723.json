{
  "thread": {
    "uuid": "785bc3d9d4fd62edcf876304089ece364b0dbc4a",
    "url": "https://davidicke.com/2025/08/14/the-godfather-of-ai-reveals-the-only-way-humanity-can-survive-superintelligent-ai/",
    "site_full": "davidicke.com",
    "site": "davidicke.com",
    "site_section": "http://blogoright.blogspot.com/",
    "site_categories": [
      "religion",
      "advertising",
      "business"
    ],
    "section_title": "BLOG-O-NEWS",
    "site_title": "David Icke &#8211; News",
    "title": "The 'godfather of AI' reveals the only way humanity can survive superintelligent AI - David Icke",
    "title_full": "The 'godfather of AI' reveals the only way humanity can survive superintelligent AI - David Icke",
    "published": "2025-08-14T03:00:00.000+03:00",
    "replies_count": 0,
    "participants_count": 1,
    "site_type": "news",
    "country": "GB",
    "main_image": "https://davidicke.com/wp-content/uploads/2023/02/AI-scaled.jpg",
    "performance_score": 0,
    "domain_rank": 19162,
    "domain_rank_updated": "2025-06-03T00:00:00.000+03:00",
    "licensing_agency": [],
    "social": {
      "facebook": {
        "likes": 0,
        "comments": 0,
        "shares": 0
      },
      "vk": {
        "shares": 0
      }
    }
  },
  "uuid": "785bc3d9d4fd62edcf876304089ece364b0dbc4a",
  "url": "https://davidicke.com/2025/08/14/the-godfather-of-ai-reveals-the-only-way-humanity-can-survive-superintelligent-ai/",
  "ord_in_thread": 0,
  "author": "@",
  "published": "2025-08-14T03:00:00.000+03:00",
  "title": "The 'godfather of AI' reveals the only way humanity can survive superintelligent AI - David Icke",
  "text": "Geoffrey Hinton, known as the “godfather of AI,” fears the technology he helped build could wipe out humanity — and “tech bros” are taking the wrong approach to stop it.\nHinton, a Nobel Prize-winning computer scientist and a former Google executive, has warned in the past that there is a 10% to 20% chance that AI wipes out humans. On Tuesday, he expressed doubts about how tech companies are trying to ensure humans remain “dominant” over “submissive” AI systems.\n“That’s not going to work. They’re going to be much smarter than us. They’re going to have all sorts of ways to get around that,” Hinton said at Ai4, an industry conference in Las Vegas.\nIn the future, Hinton warned, AI systems might be able to control humans just as easily as an adult can bribe 3-year-old with candy. This year has already seen examples of AI systems willing to deceive, cheat and steal to achieve their goals. For example, to avoid being replaced, one AI model tried to blackmail an engineer about an affair it learned about in an email.\nInstead of forcing AI to submit to humans, Hinton presented an intriguing solution: building “maternal instincts” into AI models, so “they really care about people” even once the technology becomes more powerful and smarter than humans.\nAI systems “will very quickly develop two subgoals, if they’re smart: One is to stay alive… (and) the other subgoal is to get more control,” Hinton said. “There is good reason to believe that any kind of agentic AI will try to stay alive.”\nThat’s why it is important to foster a sense of compassion for people, Hinton argued. At the conference, he noted that mothers have instincts and social pressure to care for their babies.\n“The right model is the only model we have of a more intelligent thing being controlled by a less intelligent thing, which is a mother being controlled by her baby,” Hinton said.\n‘The only good outcome’ Hinton said it’s not clear to him exactly how that can be done technically but stressed it’s critical researchers work on it.\n“That’s the only good outcome. If it’s not going to parent me, it’s going to replace me,” he said. “These super-intelligent caring AI mothers, most of them won’t want to get rid of the maternal instinct because they don’t want us to die.” Read More: The ‘godfather of AI’ reveals the only way humanity can survive superintelligent AI",
  "highlightText": "",
  "highlightTitle": "",
  "highlightThreadTitle": "",
  "language": "english",
  "sentiment": "negative",
  "categories": [
    "Science and Technology",
    "Social Issue",
    "Human Interest"
  ],
  "topics": [
    "Science and Technology->scientific research",
    "Science and Technology->information technology and computer science",
    "Science and Technology->technology and engineering",
    "Social Issue->social problem",
    "Social Issue->social networking"
  ],
  "ai_allow": true,
  "has_canonical": false,
  "breaking": null,
  "webz_reporter": false,
  "external_links": [
    "https://www.axios.com/2025/06/20/ai-models-deceive-steal-blackmail-anthropic",
    "https://www.axios.com/2025/05/23/anthropic-ai-deception-risk",
    "https://axios.com/2025/05/23/anthropic-ai-deception-risk",
    "https://axios.com/2025/06/20/ai-models-deceive-steal-blackmail-anthropic"
  ],
  "external_images": [],
  "internal_images": [],
  "entities": {
    "persons": [
      {
        "name": "David Icke",
        "sentiment": "negative"
      },
      {
        "name": "Geoffrey Hinton",
        "sentiment": "negative"
      }
    ],
    "locations": [],
    "organizations": [
      {
        "name": "Google",
        "sentiment": "none",
        "tickers": [
          {
            "ticker": "GOOG",
            "exchange": "NASDAQ"
          }
        ]
      }
    ]
  },
  "syndication": {
    "syndicated": false,
    "syndicate_id": null,
    "first_syndicated": false
  },
  "trust": {
    "categories": [],
    "top_news": [],
    "bias": null,
    "source": {
      "type": null,
      "city": null,
      "state": null,
      "country": null,
      "domain_type": null,
      "agency": null,
      "organization_name": null
    }
  },
  "rating": null,
  "crawled": "2025-08-14T08:48:01.943+03:00",
  "updated": "2025-08-14T10:05:18.926+03:00"
}