{
  "thread": {
    "uuid": "c2380b48ce0352fc319b99418a6a125edab5041f",
    "url": "https://www.ots.at/presseaussendung/OTS_20250814_OTS0004/verfassungsschutz-tendenz-zu-steigender-rolle-von-kuenstlicher-intelligenz-ki-bei-radikalisierung",
    "site_full": "www.ots.at",
    "site": "ots.at",
    "site_section": "http://www.ots.at/rss/index",
    "site_categories": [
      "media",
      "top_news_at",
      "top_news"
    ],
    "section_title": "",
    "site_title": "OTS.at - aktuelle Inhalte in Text, Bild, Ton und Video",
    "title": "Verfassungsschutz: Tendenz zu steigender Rolle von Künstlicher Intelligenz (KI) bei Radikalisierung",
    "title_full": "Verfassungsschutz: Tendenz zu steigender Rolle von Künstlicher Intelligenz (KI) bei Radikalisierung",
    "published": "2025-08-14T09:00:00.000+03:00",
    "replies_count": 0,
    "participants_count": 1,
    "site_type": "news",
    "country": "AT",
    "main_image": "https://ots-assets.cdn.apa.at/sender/1a23651a-24fb-4494-ade8-e43c286e525e/logos/a12d58c2-5b80-4e2f-a0bc-455d63779365.sm_h",
    "performance_score": 0,
    "domain_rank": 9662,
    "domain_rank_updated": "2025-06-03T00:00:00.000+03:00",
    "licensing_agency": [],
    "social": {
      "facebook": {
        "likes": 0,
        "comments": 0,
        "shares": 0
      },
      "vk": {
        "shares": 0
      }
    }
  },
  "uuid": "c2380b48ce0352fc319b99418a6a125edab5041f",
  "url": "https://www.ots.at/presseaussendung/OTS_20250814_OTS0004/verfassungsschutz-tendenz-zu-steigender-rolle-von-kuenstlicher-intelligenz-ki-bei-radikalisierung",
  "ord_in_thread": 0,
  "author": "Bundesministerium für Inneres",
  "published": "2025-08-14T09:00:00.000+03:00",
  "title": "Verfassungsschutz: Tendenz zu steigender Rolle von Künstlicher Intelligenz (KI) bei Radikalisierung",
  "text": "- 14.08.2025, 08:00:34\n- /\n- OTS0004\nVerfassungsschutz: Tendenz zu steigender Rolle von Künstlicher Intelligenz (KI) bei Radikalisierung\nDie Direktion Staatsschutz und Nachrichtendienst (DSN) warnt vor einer potenziellen Zunahme der Gefahr durch den gezielten Einsatz Künstlicher Intelligenz (KI) durch extremistische Gruppierungen. Bei den aktuellen Entwicklungen rund um KI besteht die Möglichkeit, dass zukünftig moderne KI-gestützte Systeme genutzt werden, um personalisierte Radikalisierungsstrategien zu entwickeln und dadurch gezielt Einzelpersonen für extremistische Ideologien zu gewinnen.\n„Die fortschreitende Entwicklung Künstlicher Intelligenz eröffnet extremistischen Gruppierungen gefährliche Möglichkeiten, Menschen mit maßgeschneiderter Propaganda zu radikalisieren. Wir dürfen diese neue Form der Bedrohung nicht unterschätzen. Deshalb werden wir Tendenzen in diesem Bereich ganz genau beobachten,“ so Staatssekretär Jörg Leichtfried zu den aktuellen Herausforderungen im Onlinebereich.\nDie enorme Menge an Online-Inhalten kann heute nicht mehr ausschließlich manuell überprüft werden. Daher ist davon auszugehen, dass große Plattformen und Sicherheitsbehörden zukünftig verstärkt auf automatisierte Werkzeuge zurückgreifen werden, die mittels maschinellen Lernens terroristische oder extremistische Inhalte erkennen und deren Entfernung anregen. Gleichzeitig besteht das Risiko, dass dieselben technologischen Fortschritte auch von extremistischen Akteuren adaptiert und missbraucht werden könnten. Auf diese Entwicklungen will sich der österreichische Verfassungsschutz vorbereiten.\nGezielte Ansprache durch KI-gestützte Propaganda\nModerne KI-Systeme könnten laut Verfassungsschutz künftig in der Lage sein, große Datenmengen automatisiert auszuwerten und so individuelle psychologische und soziale Merkmale von Nutzerinnen und Nutzern zu analysieren. In einem solchen Szenario könnten extremistische Organisationen diese Technologien nutzen, um maßgeschneiderte Inhalte zu entwickeln, die gezielt auf persönliche Überzeugungen, Interessen und Schwachstellen zugeschnitten sind. Denkbare Anwendungen wären unter anderem:\nAutomatisierte Analyse sozialer Medien: KI-Systeme könnten Profile von Nutzerinnen und Nutzern analysieren, um Personen mit erhöhter Anfälligkeit für radikale Inhalte zu identifizieren.\nDynamische Propagandastrategien: Es ist davon auszugehen, dass KI-Modelle personalisierte extremistische Inhalte generieren, die sich an das Verhalten und die Vorlieben der Zielpersonen anpassen.\nManipulative Chatbots und Deepfake-Technologien: Fortschrittliche KI-gesteuerte Chatbots und täuschend echte, gefälschte Videos könnten dazu genutzt werden, den Einfluss extremistischer Narrative erheblich zu verstärken.\nHerausforderungen für die Sicherheitsbehörden\nSollten sich Entwicklungen, wie die Fähigkeit dieser Systeme, in Echtzeit Inhalte zu optimieren und auf spezifische Reaktionen von Zielpersonen einzugehen, fortsetzen – wovon aktuell auszugehen ist – stellt dies die Sicherheitsbehörden vor neue Herausforderungen. Herkömmliche Überwachungs- und Gegenmaßnahmen würden hier an ihre Grenzen stoßen, da sich KI-generierte Inhalte dynamisch verändern und klassische Erkennungsmechanismen umgehen könnten.\nBesonders problematisch wäre, wenn extremistische Akteure generative KI gezielt einsetzen, um beispielsweise Verzerrungen oder Lücken in Sprach-, Bild- oder Desinformationserkennung zu finden und diese ausnutzen. Dadurch würden personalisierte Radikalisierungswege entstehen, die schwerer zu durchbrechen sind als herkömmliche Propaganda.\nNotwendigkeit neuer Gegenmaßnahmen\nDie DSN arbeitet intensiv mit nationalen und internationalen Partnern zusammen, um für die zukünftig zu erwartenden Herausforderungen gewappnet zu sein und Strategien zur Erkennung und Bekämpfung von KI-gestützter Radikalisierung zu entwickeln. Dabei wird auf folgende Ansätze gesetzt:\nErweiterte KI-gestützte Erkennungssysteme: Systeme müssen in der Lage sein, kontextuelle und dynamische Veränderungen in extremistischer Propaganda zu identifizieren.\nErhöhte Transparenz und Kontrolle über Algorithmen: Die Zusammenarbeit mit Technologieunternehmen ist entscheidend, um Manipulationsversuche frühzeitig zu erkennen.\nSensibilisierung der Öffentlichkeit: Nutzerinnen und Nutzer müssen über die neuen Methoden extremistischer Gruppierungen aufgeklärt und für personalisierte Radikalisierungsversuche sensibilisiert werden.\n„Nur mit enger Zusammenarbeit von Staat, Sicherheitsbehörden und Technologieunternehmen sowie durch Stärkung von Medienkompetenz und dem kritischen Umgang mit Online-Inhalten können wir dem voranschreitenden Extremismus im Netz entgegentreten“, sagt Leichtfried. Es gehe dabei unter anderem auch viel um die Sensibilisierung der Öffentlichkeit für KI-gesteuerte personalisierte Radikalisierungsversuche.\nExpertinnen und Experten warnen vor Extremismus durch Künstliche Intelligenz\nAnfang des Jahres 2025 fand in Wien ein Symposium des CSAIR (Center for Security Analysis and Intelligence Research) der DSN statt, bei dem Expertinnen und Experten aus Wissenschaft, Politik und Sicherheitsbehörden über aktuelle Entwicklungen und Herausforderungen im Bereich des Extremismus diskutierten. Ein zentrales Thema war der Missbrauch von KI durch extremistische Gruppen. Einer der Vortragenden, David Wells vom Asscociate Cyber Threats Resarch Centre an der Swansea University in Wales, machte in seinem Vortrag deutlich, dass insbesondere generative KI zunehmend zur Verbreitung von Propaganda, zur Erstellung täuschend echter Deepfake Videos und zur personalisierten Radikalisierung eingesetzt wird. Diese Technologien stellen Sicherheitsbehörden und Social Media Plattformen vor neue Herausforderungen, eröffnen aber gleichzeitig auch neue Möglichkeiten zur Bekämpfung extremistischer Inhalte. Die Teilnehmerinnen und Teilnehmer des Symposiums betonten die Notwendigkeit einer engen Zusammenarbeit zwischen staatlichen Institutionen, Technologieunternehmen und der Wissenschaft, um diesen Bedrohungen wirksam entgegenzutreten.\nRückfragen & Kontakt\nBundesministerium für Inneres\nAbteilung I/C/10 - Öffentlichkeitsarbeit\nRessortsprecher des Bundesministeriums für Inneres\nTelefon: +43 (0) 1-531 26 - 90 15 62\nE-Mail: bmi-ressortsprecher@bmi.gv.at\nWebsite: https://www.bmi.gv.at\nOTS-ORIGINALTEXT PRESSEAUSSENDUNG UNTER AUSSCHLIESSLICHER INHALTLICHER VERANTWORTUNG DES AUSSENDERS - WWW.OTS.AT | NIN",
  "highlightText": "",
  "highlightTitle": "",
  "highlightThreadTitle": "",
  "language": "german",
  "sentiment": "negative",
  "categories": [
    "Politics",
    "Social Issue",
    "Science and Technology"
  ],
  "topics": [
    "Politics->political development",
    "Politics->government",
    "Politics->civil rights",
    "Social Issue->communities",
    "Social Issue->social problem",
    "Social Issue->demographics",
    "Science and Technology->social sciences",
    "Science and Technology->technology and engineering",
    "Science and Technology->psychology"
  ],
  "ai_allow": true,
  "has_canonical": false,
  "breaking": true,
  "webz_reporter": false,
  "external_links": [
    "https://www.bmi.gv.at",
    "https://bmi.gv.at"
  ],
  "external_images": [],
  "internal_images": [],
  "entities": {
    "persons": [
      {
        "name": "Jörg Leichtfried",
        "sentiment": "none"
      }
    ],
    "locations": [],
    "organizations": []
  },
  "syndication": {
    "syndicated": null,
    "syndicate_id": null,
    "first_syndicated": false
  },
  "trust": {
    "categories": [],
    "top_news": [
      "top_news_at",
      "top_news"
    ],
    "bias": null,
    "source": {
      "type": null,
      "city": null,
      "state": null,
      "country": null,
      "domain_type": null,
      "agency": null,
      "organization_name": null
    }
  },
  "rating": null,
  "crawled": "2025-08-14T09:10:33.798+03:00",
  "updated": "2025-08-15T10:10:36.000+03:00"
}