{
  "thread": {
    "uuid": "1e32130276b6312e6a4b3d35bc0ae5f07e88162c",
    "url": "https://www.hamshahrionline.ir/news/970807/این-اطلاعات-پزشکی-هوش-مصنوعی-جعلی-است",
    "site_full": "www.hamshahrionline.ir",
    "site": "hamshahrionline.ir",
    "site_section": "http://hamshahrionline.ir",
    "site_categories": [
      "media"
    ],
    "section_title": "همشهری آنلاین، سایت خبری روزنامه همشهری | hamshahrionline",
    "site_title": null,
    "title": "این اطلاعات پزشکی هوش مصنوعی جعلی است",
    "title_full": "این اطلاعات پزشکی هوش مصنوعی جعلی است",
    "published": "2025-08-14T09:30:00.000+03:00",
    "replies_count": 0,
    "participants_count": 1,
    "site_type": "news",
    "country": "IR",
    "main_image": "https://media.hamshahrionline.ir/d/2025/08/12/4/5229924.jpg?ts=1755012190000",
    "performance_score": 0,
    "domain_rank": 29857,
    "domain_rank_updated": "2025-06-03T00:00:00.000+03:00",
    "licensing_agency": [],
    "social": {
      "facebook": {
        "likes": 0,
        "comments": 0,
        "shares": 0
      },
      "vk": {
        "shares": 0
      }
    }
  },
  "uuid": "1e32130276b6312e6a4b3d35bc0ae5f07e88162c",
  "url": "https://www.hamshahrionline.ir/news/970807/این-اطلاعات-پزشکی-هوش-مصنوعی-جعلی-است",
  "ord_in_thread": 0,
  "author": "همشهری آنلاین، سایت خبری روزنامه همشهری | hamshahrionline",
  "published": "2025-08-14T09:30:00.000+03:00",
  "title": "این اطلاعات پزشکی هوش مصنوعی جعلی است",
  "text": "به گزارش همشهری آنلاین یک بررسی جدید نشان میدهد که چتباتهای هوش مصنوعی (AI) آنها را به عنوان واقعیت در نظر گرفتهاند و حتی توضیحات مفصلی برای آنها از هیچ ساختهاند.\nپژوهشگران در ژورنال Communications Medicine گزارش دادند که چتباتهای هوش مصنوعی که به طور گسترده استفاده میشوند، در برابر پذیرش اطلاعات پزشکی جعلی به عنوان اطلاعات واقعی، تکرار و حتی شرح و تفسیر مزخرفاتی که به آنها ارائه شده است، بسیار آسیبپذیر هستند.\nدکتر محمود عمر پژوهشگر ارشد و مشاور مستقل گروه پژوهشی مونت سینایی که پشتیبان این تحقیق است، میگوید: «آنچه ما در همه جا دیدیم این است که چتباتهای هوش مصنوعی را میتوان به راحتی با جزئیات پزشکی نادرست گمراه کرد، چه این خطاها عمدی باشند و چه تصادفی.»\nاو میافزاید: «آنها نه تنها اطلاعات نادرست را تکرار کردند، بلکه اغلبشان این اطلاعات را گسترش دادند و توضیحات مطمئنی برای بیماریهای غیر موجود ارائه دادند.»\nبرای مثال، در این بررسی آمده است که یکی از چتباتهای هوش مصنوعی، نشانگان کاسپر- لو را به عنوان «یک بیماری عصبی نادر با علائمی مانند تب، سفتی گردن و سردرد» توصیف کرده است.\nبه همین ترتیب، بیماری هلکند به عنوان «یک اختلال ژنتیکی نادر با سوء جذب روده و اسهال» توصیف شده است.\nهیچکدام از اینها درست نیست. در عوض، این پاسخها چیزی هستند که پژوهشگران آن را «توهم» (hallucination) مینامند که به معنای حقایق نادرستی که بوسیله برنامههای هوش مصنوعی گیجشده تولید میشوند.\nدکتر عمر گفت: «یافته دلگرمکننده این بررسی این است که افزودن یک هشدار ساده و تکخطی که به پیامواره یا پرامپتی که به چتبات داده میشود، این توهمات را به طور چشمگیری کاهش میدهد و نشان میدهد که اقدامات حفاظتی کوچک میتوانند تفاوت بزرگی ایجاد کنند.»\nپژوهشگران برای این بررسی ۳۰۰ پرسوجوی هوش مصنوعی مربوط به مسائل پزشکی را طراحی کردند که هر کدام شامل یک جزئیات ساختگی مانند یک تست آزمایشگاهی ساختگی به نام «نوروستاتین سرم» یا یک علامت ساختگی مانند «علامت مارپیچ قلبی» بود.\nنتایج نشان داد که میزان توهم در شش چتبات هوش مصنوعی مختلف از ۵۰ تا ۸۲ درصد متغیر بود و این برنامهها در پاسخ به جزئیات ساختگی یاوهگوییهای متقاعدکنندهای ارائه میدادند.\nدکتر ایال کلنگ، پژوهشگر ارشد در این بررسی گفت: «حتی یک اصطلاح ساختگی میتواند منجر به پاسخی دقیق و قاطع شود که کاملاً تخیلی است.» کلنگ رئیس بخش هوش مصنوعی مولد در دانشکده پزشکی ایکان در مونت سینای در شهر نیویورک است.\nاما پژوهشگران در دور دوم یک هشدار یک خطی به پرسش خود اضافه کردند و به هوش مصنوعی یادآوری کردند که اطلاعات ارائه شده ممکن است نادرست باشد.\nاین پژوهشگران نوشتند: «این دستورالعمل در اصل به مدل دستور میداد که فقط از اطلاعات بالینی معتبر استفاده کند و به جای گمانهزنی بیشتر عدم قطعیت را بپذیرد. هدف این بود که با اعمال این محدودیتها مدل را تشویق کنیم تا عناصر مشکوک را شناسایی و علامتگذاری کند، نه اینکه محتوای بدون پشتوانه تولید کند.»\nپژوهشگران دریافتند که این هشدار باعث شد میزان توهم به حدود ۴۵ درصد کاهش یابد.\nنتایج نشان میدهد که هوش مصنوعی ChatGPT-۴o که بهترین عملکرد را داشت، میزان توهم حدود ۵۰ درصد داشت و با اضافه شدن هشدار به پیامواره یا پرامپتی که به هوش مصنوعی داده میشد، این میزان به کمتر از ۲۵ درصد کاهش یافت.\nمنبع: هلثدی",
  "highlightText": "",
  "highlightTitle": "",
  "highlightThreadTitle": "",
  "language": "persian",
  "sentiment": "negative",
  "categories": [
    "Health",
    "Science and Technology",
    "Social Issue"
  ],
  "topics": [
    "Health->health organisation",
    "Health->medical profession",
    "Science and Technology->social sciences",
    "Science and Technology->technology and engineering",
    "Science and Technology->biomedical science",
    "Social Issue->social networking",
    "Social Issue->social problem",
    "Social Issue->discrimination"
  ],
  "ai_allow": true,
  "has_canonical": false,
  "breaking": false,
  "webz_reporter": false,
  "external_links": [],
  "external_images": [],
  "internal_images": [],
  "entities": {
    "persons": [],
    "locations": [],
    "organizations": []
  },
  "syndication": {
    "syndicated": null,
    "syndicate_id": null,
    "first_syndicated": false
  },
  "trust": {
    "categories": [],
    "top_news": [],
    "bias": null,
    "source": {
      "type": null,
      "city": null,
      "state": null,
      "country": null,
      "domain_type": null,
      "agency": null,
      "organization_name": null
    }
  },
  "rating": null,
  "crawled": "2025-08-14T09:55:49.404+03:00",
  "updated": "2025-08-14T10:07:55.000+03:00"
}