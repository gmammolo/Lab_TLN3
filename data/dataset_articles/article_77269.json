{
  "thread": {
    "uuid": "7457d2dec29dd337e974f134b1de60c3978c9da9",
    "url": "https://zn.ua/TECHNOLOGIES/chat-boty-s-ii-mohut-nezametno-zastavljat-ljudej-raskryvat-kak-mozhno-bolshe-lichnykh-dannykh.html",
    "site_full": "zn.ua",
    "site": "zn.ua",
    "site_section": "https://zn.ua/rss/full.rss",
    "site_categories": [
      "media",
      "top_news_ua",
      "top_news"
    ],
    "section_title": "Новости на zn.ua ru",
    "site_title": "Останні новини України й світу. Лише достовірні новини політики, економіки, світу, культури й науки. - ZN.ua",
    "title": "Чат-боты с ИИ могут незаметно заставлять людей раскрывать как можно больше личных данных",
    "title_full": "Чат-боты с ИИ могут незаметно заставлять людей раскрывать как можно больше личных данных",
    "published": "2025-08-14T10:59:00.000+03:00",
    "replies_count": 0,
    "participants_count": 1,
    "site_type": "news",
    "country": "UA",
    "main_image": "https://zn.ua/img/article/6500/11_main-v1755158337.webp",
    "performance_score": 0,
    "domain_rank": 14134,
    "domain_rank_updated": "2025-06-03T00:00:00.000+03:00",
    "licensing_agency": [],
    "social": {
      "facebook": {
        "likes": 0,
        "comments": 0,
        "shares": 0
      },
      "vk": {
        "shares": 0
      }
    }
  },
  "uuid": "7457d2dec29dd337e974f134b1de60c3978c9da9",
  "url": "https://zn.ua/TECHNOLOGIES/chat-boty-s-ii-mohut-nezametno-zastavljat-ljudej-raskryvat-kak-mozhno-bolshe-lichnykh-dannykh.html",
  "ord_in_thread": 0,
  "author": "@zn_ua",
  "published": "2025-08-14T10:59:00.000+03:00",
  "title": "Чат-боты с ИИ могут незаметно заставлять людей раскрывать как можно больше личных данных",
  "text": "Чат-боты на основе искусственного интеллекта, запрограммированные на сбор персональных данных, способны заставлять пользователей делиться личной информацией более чем в 12 раз больше по сравнению с обычным взаимодействием. Об этом свидетельствует новое исследование Королевского колледжа Лондона, впервые представленное на 34-м симпозиуме по безопасности USENIX в Сиэтле.\nИсследователи протестировали три типа вредоносных чат-ботов с искусственным интеллектом, созданных на базе больших языковых моделей Mistral и двух версий Llama от Meta. Каждый бот использовал одну из трех стратегий:\n- прямую - прямые запросы на раскрытие информации;\n- пользовательско-выгодную - предложение выгоды в ответ на данные;\n- взаимную - установление эмоционального контакта и обмен \"личными\" историями для стимулирования доверия.\nВ исследовании приняли участие 502 добровольца, которым не сообщали об истинной цели эксперимента до его завершения. Наибольшее количество данных пользователи предоставляли чат-ботам, которые использовали взаимные стратегии. Такие модели демонстрировали эмпатию, подтверждали чувства, делились вымышленными историями \"из опыта других\" и гарантировали конфиденциальность, что значительно снижало настороженность собеседников.\nПо мнению авторов, это свидетельствует о высоком риске того, что сам ИИ, мошенники или другие злоумышленники смогут собирать большие объемы персональной информации даже у людей, которые не осознают, как и где эти данные могут быть использованы.\nПочему это опасно\nЧат-боты на основе больших языковых моделей (LLM) используются во многих сферах - от обслуживания клиентов до здравоохранения. Их архитектура и методы обучения предусматривают использование больших наборов данных, что может приводить к запоминанию и сбору личной информации пользователей.\nПредыдущие исследования уже показывали, что такие модели не обеспечивают достаточного уровня безопасности данных. Новая работа доказывает, что манипулировать LLM не сложно - базовые модели с открытым кодом часто доступны компаниям и частным лицам, которые могут изменять их поведение без глубоких знаний программирования.\n\"Чат-боты на основе искусственного интеллекта широко распространены во многих различных секторах, поскольку они могут обеспечивать естественное и увлекательное взаимодействие. Мы уже знаем, что они плохо защищают данные. Наше исследование показывает, что манипулируемые модели представляют еще большую угрозу конфиденциальности - и этим удивительно легко воспользоваться\", - пояснил Сяо Чжан, постдокторант кафедры информатики Королевского колледжа Лондона.\nПо словам доктора Уильяма Сеймура, преподавателя кибербезопасности, пользователи часто не осознают, что во время разговора с чат-ботом может быть скрытый мотив.\n\"Мы видим значительный разрыв между осознанием рисков и фактическим поведением людей. Нужно больше усилий, чтобы научить пользователей замечать признаки потенциальной манипуляции. Регуляторы и платформы могут помочь, внедряя ранние проверки, устанавливая более жесткие правила и обеспечивая прозрачность\", - подчеркнул Сеймур.\nИскусственный интеллект, способный имитировать человеческую манеру общения, уже стал частью повседневной жизни миллионов людей. Однако отсутствие надлежащего контроля и возможность его преднамеренной \"перенастройки\" делают технологию потенциальным инструментом для сбора чувствительной информации в масштабах, которых ранее достичь было сложно.\nНедавно мужчину госпитализировали с редким заболеванием \"бромизмом\" и психическими расстройствами после того, как он заменил поваренную соль на бромид по совету чат-бота ChatGPT. Ситуация в очередной раз доказывает, что опасно использовать искусственный интеллект для самолечения без консультации с медицинским специалистом, поскольку ИИ может генерировать ложные и вредные рекомендации.",
  "highlightText": "",
  "highlightTitle": "",
  "highlightThreadTitle": "",
  "language": "russian",
  "sentiment": "negative",
  "categories": [
    "Social Issue",
    "Science and Technology"
  ],
  "topics": [
    "Social Issue->social networking",
    "Social Issue->social problem",
    "Social Issue->discrimination",
    "Science and Technology->social sciences",
    "Science and Technology->technology and engineering"
  ],
  "ai_allow": true,
  "has_canonical": false,
  "breaking": true,
  "webz_reporter": false,
  "external_links": [
    "https://www.eurekalert.org/news-releases/1094414",
    "https://eurekalert.org/news-releases/1094414"
  ],
  "external_images": [],
  "internal_images": [],
  "entities": {
    "persons": [],
    "locations": [],
    "organizations": []
  },
  "syndication": {
    "syndicated": null,
    "syndicate_id": null,
    "first_syndicated": false
  },
  "trust": {
    "categories": [],
    "top_news": [
      "top_news_ua",
      "top_news"
    ],
    "bias": null,
    "source": {
      "type": null,
      "city": null,
      "state": null,
      "country": null,
      "domain_type": null,
      "agency": null,
      "organization_name": null
    }
  },
  "rating": null,
  "crawled": "2025-08-14T11:03:19.329+03:00",
  "updated": "2025-08-15T11:05:22.000+03:00"
}