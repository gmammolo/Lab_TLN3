{
  "thread": {
    "uuid": "9ec05ca5e07c444471791507d40d93e7fca25438",
    "url": "https://www.sealynews.com/node/89553",
    "site_full": "www.sealynews.com",
    "site": "sealynews.com",
    "site_section": "https://sealynews.com/stacker/science",
    "site_categories": [
      "media"
    ],
    "section_title": "Stacker News | The Sealy News",
    "site_title": "The Sealy News",
    "title": "AI impersonation scams are exploding: Here's how to spot and stop them | The Sealy News",
    "title_full": "AI impersonation scams are exploding: Here's how to spot and stop them | The Sealy News",
    "published": "2025-07-28T03:00:00.000+03:00",
    "replies_count": 0,
    "participants_count": 1,
    "site_type": "news",
    "country": "US",
    "main_image": "",
    "performance_score": 0,
    "domain_rank": 775908,
    "domain_rank_updated": "2025-06-03T00:00:00.000+03:00",
    "licensing_agency": [],
    "social": {
      "facebook": {
        "likes": 0,
        "comments": 0,
        "shares": 0
      },
      "vk": {
        "shares": 0
      }
    }
  },
  "uuid": "9ec05ca5e07c444471791507d40d93e7fca25438",
  "url": "https://www.sealynews.com/node/89553",
  "ord_in_thread": 0,
  "author": "Evan Ullman",
  "published": "2025-07-28T03:00:00.000+03:00",
  "title": "AI impersonation scams are exploding: Here's how to spot and stop them | The Sealy News",
  "text": "Linaimages // Shutterstock\nAI impersonation scams are exploding: Here's how to spot and stop them\nThe conversational AI market is exploding. Grand View Research suggests it's set to jump from $11.58 billion in 2024 to $41.39 billion by 2030, a massive 23.7% annual growth rate. While businesses use AI to boost customer service, cybercriminals are jumping in too, launching slick impersonation scams.\nThese scams are spreading fast. A report from the Identity Theft Resource Center shows a 148% spike in impersonation scams between April 2024 and March 2025 as scammers spin up fake business websites, create lifelike AI chatbots, and build voice agents that sound just like real company reps. In 2024 alone, the Federal Trade Commission reported $2.95 billion in losses due to impersonation scams.\nHeimdal breaks down how scammers fake customer service, points out the industries they hit hardest, and shares simple ways to double-check who you’re talking to before giving up your personal info.\nThe technology behind the deception\nToday’s AI scams blend high-tech tools with surprisingly simple methods, making impersonation easier than ever.\nHow AI powers slick impersonation\nVoice cloning has gotten scarily accurate. McAfee notes that with just three seconds of audio, scammers can copy someone’s voice so well that in its study of 7,000 people, 70% weren’t confident enough to tell if the voice was real or a clone.\nAI chatbots have also leveled up. They mirror tone, language, and responses so well they’re almost impossible to tell apart from real customer service reps.\nOn top of both, fake website creation has exploded. AI can whip up polished product descriptions, realistic images, and fake reviews that look legit — all in minutes.\nFraud is easier than ever\nStarting an AI scam is cheap and fast. According to a 2024 Deloitte study, scamming software sells on the dark web for as little as $20. Scams can not only be cheap, but they work fast: Consumer advice charity Advance Direct Scotland found that an AI scam can go live in under two minutes.\nThese low costs and easy access have supercharged growth. Open-source fraud reporting platform Chainabuse reports that generative AI scams quadrupled between May 2024 and April 2025.\nMore than 38,000 new scam pages popped up every day in the first half of 2024, according to Security Boulevard. The mix of powerful tech and easy access makes AI business impersonation one of the fastest-growing threats facing consumers today.\nIndustries under siege: Most targeted sectors\nNo industry is completely safe from AI impersonation scams, but some face much bigger risks because of the sensitive data and money they handle.\nFinancial services: The primary target\nThe financial sector sits at the top of scammers’ hit list. The Financial Crimes Enforcement Network warned U.S. banks in November 2024 about the surge in AI-powered identity fraud.\nDeloitte expects U.S. banking fraud losses to soar from $12.3 billion in 2023 to $40 billion by 2027. Signicat’s Battle Against AI-driven Identity Fraud report, based on February 2024 data, found that AI drives over 42% of all fraud.\nE-commerce and retail\nOnline shopping platforms are another favorite target. According to Juniper Research, e-commerce fraud is projected to rocket from $44.3 billion in 2024 to a staggering $107 billion by 2029. Microsoft has exposed scams using fake shopping sites and AI chatbots designed to harvest payment details and personal info.\nMost impersonated entities\nScammers love going after businesses. Identity Theft Resource Center’s 2025 report notes that about 51% of impersonation scams target them directly, while 21% focus on financial institutions, all rich with data that scammers crave.\nAs AI scams keep evolving, businesses in these industries need to stay alert and rethink their defenses to keep up with this fast-moving threat.\nAnatomy of modern AI scams: Real-world case studies\nLooking at actual incidents shows just how sophisticated and convincing AI-powered scams have become, even fooling cautious, tech-savvy individuals.\nThe $25 million deepfake video conference scam\nIn one of the most shocking cases to date, a Hong Kong finance worker was tricked into transferring 200 million Hong Kong dollars (about $25.6 million) after attending a deepfake video call with what appeared to be the company’s chief financial officer and other senior colleagues.\nThe employee initially suspected a phishing attempt but was convinced by a highly realistic video conference. Scammers used publicly available video footage to create AI-generated versions of each participant, perfectly mimicking voices and facial expressions to make the fake meeting appear completely authentic.\nTech company CEO impersonations\nCybercriminals have increasingly targeted tech companies by impersonating top executives. At the company LastPass, an employee received calls, texts, and WhatsApp messages from someone posing as the CEO. The voice was cloned using audio taken from YouTube videos.\nAt cloud security firm Wiz, scammers used an AI-generated voice clone of the CEO to leave voicemails for dozens of employees, asking for sensitive credentials. In both cases, the impersonations were realistic enough to almost trick seasoned security professionals.\nConsumer-facing scams\nAI scams aren’t limited to corporate environments. In Canada, three men lost a combined 373,000 Canadian dollars (over $273,000) after being convinced by deepfake videos featuring what appeared to be Justin Trudeau and Elon Musk promoting a fake investment scheme.\nVoice cloning scams are also widespread. In the McAfee study, 10% of respondents received a message from an AI voice clone. Of those targeted, 77% reported financial losses.\nThe ‘scam sweatshop’ operation\nAccording to The Sunday Post, authorities in Scotland uncovered so-called AI “scam sweatshops,” where criminals generated hyperpersonalized fraud campaigns in under two minutes using freely available AI apps. These operations swindled over 700,000 pounds (more than $945,000) from Scots through highly targeted voice and text-based scams.\nThese real-world examples highlight a sobering reality: AI-driven scams are no longer crude or obvious; they are highly advanced and often indistinguishable from legitimate interactions.\nRegulatory response: The FTC fights back\nAs AI-powered impersonation scams have exploded, regulators have scrambled to keep up. Leading the charge, the FTC has rolled out new rules to protect both consumers and businesses.\nThe Government and Business Impersonation Rule\nLaw firm WilmerHale explains that the FTC’s Impersonation Rule, which took effect in April 2024, makes it illegal to materially and falsely pose as a government agency or business. This landmark rule gives the FTC the power to move fast against scammers running fake websites, pushing fraudulent chatbots, or using AI voice agents to mislead people.\nViolators face fines of up to $53,088 per violation. The rule also allows the FTC to drag scammers into federal court to secure refunds for victims, a big step in helping people get their money back.\nFirst-year results\nThe FTC didn’t waste time. In its first year, the agency filed five enforcement actions under the new rule and shut down 13 fake websites posing as the commission itself.\nThe FTC also launched \"Operation AI Comply,\" a crackdown on AI-powered fraud. This effort has targeted AI chatbots offering fake “legal advice” and tools flooding review sites with phony testimonials, all designed to erode public trust.\nProposed extensions\nScams keep evolving, and the FTC knows it. ReadWrite notes that the agency has proposed expanding the rule to cover impersonation of individuals, a direct move against voice cloning and deepfake scams that can mimic real people almost perfectly.\nThese regulatory moves mark a strong first step. But they also show that fighting AI scams will require constant vigilance from both regulators and the public.\nRed flags: How to spot AI impersonation\nEven the most polished AI scams leave small tells. Learning to catch these clues can help you avoid falling for them.\nChatbot warning signs\nResponse patterns: If a chatbot replies instantly and flawlessly every time, be cautious. While quick responses are normal, perfect spelling and grammar — combined with robotic or awkward phrasing — often point to AI, not a human.\nBehavioral red flags: Be wary if the bot repeats itself often or keeps pushing one solution. Real reps usually offer options and handle specific questions smoothly. AI bots tend to struggle when the conversation goes off-script.\nTechnical signs: Bots often have uniform response delays, no matter how complex the question is. They’re also available 24/7 without normal staffing patterns.\nVoice cloning detection\nAudio quality issues: Listen for weird pauses, odd tone shifts, or strange audio glitches. AI voices usually miss the natural emotion and flow of real speech.\nConversation patterns: Scammers using cloned voices often keep calls short and urgent to avoid questions. If someone you know sounds “off” or acts strangely, don’t ignore it.\nWebsite and email verification\nVisual inspection: Real business websites generally show full contact details, including a physical address, phone number, and official email. Look for security badges and seals from trusted organizations.\nCommunication channels: When in doubt, go straight to the source. Call or email using contact info from official statements or the company’s main website, not links from pop-ups or emails.\nSpotting these signals and taking a moment to double-check can stop a scam before it even starts.\nProtection Strategies: Your Defense Against AI Scams\nOnce you learn to spot impersonation attempts, the next step is building strong defenses. A mix of smart habits and proactive strategies can make a huge difference in keeping you safe.\nImmediate verification steps\nMultichannel confirmation: Always double-check unexpected requests, even if the number seems familiar. If a chatbot or caller asks for sensitive info or urgent payments, hang up or close the chat. Then, reach out directly through an official phone number or email from the company’s website.\nFamily and business protocols: Set up a “safe word” with family to confirm emergencies. For businesses, employers can implement dual approval for transactions so no single person can approve large payments alone.\nDigital hygiene practices\nVoice protection: Consider using automated voicemail greetings instead of your own voice to cut down cloning risks. Avoid sharing voice data online, a habit worth building since 53% of adults share voice recordings weekly without thinking about the risks, according to McAfee’s report.\nInformation sharing: Never share passwords, Social Security numbers, or financial details over chat, email, or phone unless you’re absolutely sure who you’re talking to. Be extra cautious with urgent or pushy requests.\nBusiness security measures\nEmployee training: Teach employees about new AI impersonation tactics. Regularly update them on scam trends and make sure they know the steps to verify any requests involving sensitive data or large payments.\nTechnical safeguards: Use multifactor authentication to reduce the risk of unauthorized access. Another common suggestion is checking financial statements and account activity often to catch suspicious transactions early.\nCombining sharp habits, solid tech tools, and clear protocols gives you the best defense against fast-evolving AI scams.\nStaying ahead of the AI arms race\nAI has completely reshaped the fraud game. Putting advanced tools into almost anyone’s hands allows scammers to pull off schemes that used to require elite hacking skills. Because of this, old-school detection methods just can’t keep up.\nBut despite these challenges, consumers still have strong ways to fight back. Using solid verification habits and staying skeptical are some of the best defenses for keeping personal and financial info safe.\nOn the regulatory side, the FTC’s tough enforcement of the Impersonation Rule shows the government is serious about stopping AI-powered scams. New proposals, such as expanding the rule to cover individual impersonation, show policymakers are adjusting to keep pace with fast-changing threats.\nLooking forward, AI scams will only get more advanced, so our awareness and defenses need to evolve too. Staying informed, regularly updating security habits, and sharing what you learn with others will be key to staying safe.\nIf you think you’ve run into an AI impersonation scam, report it at ReportFraud.ftc.gov. Your quick action protects you and helps authorities spot new threats, keeping others from getting caught in the same traps.\nThis story was produced by Heimdal and reviewed and distributed by Stacker.",
  "highlightText": "",
  "highlightTitle": "",
  "highlightThreadTitle": "",
  "language": "english",
  "sentiment": "negative",
  "categories": [
    "Crime, Law and Justice",
    "Science and Technology",
    "Social Issue"
  ],
  "topics": [
    "Crime, Law and Justice->cyber crime",
    "Crime, Law and Justice->fraud",
    "Science and Technology->information technology and computer science",
    "Science and Technology->social sciences",
    "Science and Technology->technology and engineering",
    "Social Issue->social networking",
    "Social Issue->social problem",
    "Social Issue->abusive behaviour"
  ],
  "ai_allow": true,
  "has_canonical": true,
  "breaking": null,
  "webz_reporter": false,
  "external_links": [
    "https://www.signicat.com/the-battle-against-ai-driven-identity-fraud",
    "https://www.ftc.gov/news-events/news/press-releases/2025/04/ftc-highlights-actions-protect-consumers-impersonation-scams#:~:text=Impersonation%20scams%20are%20among%20the%20top%20reported%20frauds%20to%20the%20FTC%2C%20with%20losses%20totaling%20%242.95%20billion%20in%202024",
    "https://www.sundaypost.com/fp/ai-scam-sweatshops/#:~:text=Advice%20Direct%20Scotland%20said%20international%20fraudsters%20are%20creating%20sophisticated%20scams%20in%20under%20two%20minutes%20using%20freely%20available%20AI%20apps%20such%20as%20ChatGPT.",
    "https://reportfraud.ftc.gov",
    "https://cybernews.com/news/deepfake-video-conference-call-hong-kong/#:~:text=Deepfake%20technology%20was%20used%20to%20turn%20publicly%20available%20video%20and%20other%20footage%20of%20staff%20members%20into%20convincing%20meeting%20participants.%20The%20entire%20episode%20lasted%20a%20week.",
    "https://www.fincen.gov/news/news-releases/fincen-issues-alert-fraud-schemes-involving-deepfake-media-targeting-financial",
    "https://www.idtheftcenter.org/post/2025-trends-in-identity-report-impersonation-scams-rise/",
    "https://www.zdnet.com/article/ai-unleashes-more-advanced-scams-heres-what-to-look-out-for-and-how-to-stay-protected/#:~:text=Bad%20actors%20can%20use%20this%20capability%20to%20create%20fraudulent%20websites%20that%20are%20visually%20indistinguishable%20from%20real%20ones%20with%20AI%2Dgenerated%20product%20descriptions%2C%20images%2C%20and%20even%20reviews.",
    "https://www.ctvnews.ca/toronto/article/its-scary-3-ontario-men-lose-373000-to-crypto-investment-fraud/",
    "https://techcrunch.com/2024/10/28/wiz-ceo-says-company-was-targeted-with-deepfake-attack-that-used-his-voice/",
    "https://www.idtheftcenter.org/wp-content/uploads/2025/06/2025-ITRC-Trends-in-Identity-Report.pdf",
    "https://www.ftc.gov/news-events/news/press-releases/2024/09/ftc-announces-crackdown-deceptive-ai-claims-schemes#:~:text=The%20Federal%20Trade%20Commission%20is%20taking%20action%20against%20multiple%20companies%20that%20have%20relied%20on%20artificial%20intelligence%20as%20a%20way%20to%20supercharge%20deceptive%20or%20unfair%20conduct%20that%20harms%20consumers%2C%20as%20part%20of%20its%20new%20law%20enforcement%20sweep%20called%20Operation%20AI%20Comply.",
    "https://www.mcafee.com/ai/news/ai-voice-scam/#:~:text=70%25%20of%20people%20in%20our%20worldwide%20survey%20said%20they%20weren%E2%80%99t%20confident%20they%20could%20tell%20the%20difference%20between%20a%20cloned%20voice%20and%20the%20real%20thing",
    "https://www.eftsure.com/blog/cyber-crime/these-7-deepfake-ceo-scams-prove-that-no-business-is-safe/#:~:text=But%20in%20early%202024%2C%20an%20employee%20received%20calls%2C%20texts%2C%20and%20voicemail%20from%20someone%20impersonating%20the%20company%27s%20CEO%20on%20WhatsApp.",
    "https://www.cnet.com/personal-finance/ai-voice-clones-let-scammers-spoof-your-loved-ones-and-take-your-money/#:~:text=Scammers%20need%20as%20little%20as%203%20seconds%20to%20make%20a%20decent%20simulation%20of%20a%20voice%2C%20according%20to%20the%20McAfee%20study.",
    "https://www.wilmerhale.com/en/insights/client-alerts/20240223-ftc-proposes-rule-to-make-impersonating-government-entities-and-businesses-unlawful#:~:text=prohibiting%20fraudulent%20impersonation%20of%20governments%2C%20businesses%20and%20their%20officers.",
    "https://readwrite.com/ftc-rule-finalized-governments-and-business-protected-from-ai-impersonation-scams/#:~:text=Further%2C%20the%20FTC%20proposes%20extending%20the%20new%20rule%20that%20safeguards%20governments%20and%20corporations%2C%20adding%20a%20civil%20penalty%20for%20employing%20AI%20to%20impersonate%20people.",
    "https://www.ftc.gov/news-events/news/press-releases/2025/04/ftc-highlights-actions-protect-consumers-impersonation-scams#:~:text=since%20the%20Government%20and%20Business%20Impersonation%20Rule%20took%20effect%20in%20April%202024.",
    "https://www.trmlabs.com/resources/blog/ai-enabled-fraud-how-scammers-are-exploiting-generative-ai",
    "https://heimdalsecurity.com/",
    "https://securityboulevard.com/2024/08/the-golden-age-of-impersonation-the-dual-role-of-ai-in-cyber-attacks-cyber-defense/#:~:text=Here%E2%80%99s%20the%20reality%20for%20brands%20and%20businesses%3A%20more%20than%2038%2C000%20new%20scam%20pages%20were%20created%20daily%20during%20the%20first%20half%20of%202024%2C%20driven%20primarily%20by%20the%20threat%20actor%E2%80%99s%20desire%20to%20fool%20the%20masses%20with%20greater%20sophistication%20and%20complexity%20with%20hopes%20of%20financial%20gain%20as%20a%20result.%C2%A0",
    "https://www.deloitte.com/us/en/insights/industry/financial-services/deepfake-banking-fraud-risk-on-the-rise.html",
    "https://www.ftc.gov/news-events/news/press-releases/2025/04/ftc-highlights-actions-protect-consumers-impersonation-scams#:~:text=Companies%20or%20individuals%20that%20violate%20the%20Impersonation%20Rule%20may%20be%20required%20to%20pay%20refunds%20to%20affected%20consumers%20and%20civil%20penalties%20of%20up%20to%20%2453%2C088%20per%20violation.",
    "https://heimdalsecurity.com",
    "https://www.crif.com/knowledge-events/resources/chatbots-arent-your-friend-so-be-careful-what-you-share/#:~:text=Fraudulent%20AI%20and%20chatbots%20are%20crafted%20to%20mimic%20legitimate%20services%2C%20and%20are%20often%20indistinguishable%20from%20their%20authentic%20counterparts%20to%20the%20untrained%20eye.",
    "https://www.grandviewresearch.com/industry-analysis/conversational-ai-market-report#:~:text=The%20global%20conversational%20AI%20market%20size%20was%20estimated%20at%20USD%2011.58%20billion%20in%202024%20and%20is%20projected%20to%20reach%20USD%2041.39%20billion%20by%202030%2C",
    "https://futurecio.tech/ai-assisted-scams-on-the-rise-targeting-e-shoppers-and-job-seekers/#:~:text=Microsoft%27s%20latest%20Cyber%20Signals%20report%20reveals%20AI%2Dassisted%20scams%20targeting%20e%2Dshoppers%20and%20job%20seekers.%C2%A0",
    "https://www.ftc.gov/news-events/news/press-releases/2025/04/ftc-highlights-actions-protect-consumers-impersonation-scams#:~:text=In%20the%20first%20year%20since%20the%20Rule%20went%20into%20effect%2C%20the%20FTC%20has%20brought%20five%20cases%20involving%20alleged%20violations%20and%20shut%20down%2013%20websites%20that%20were%20illegally%20impersonating%20the%20Commission%20online.",
    "https://heimdalsecurity.com/blog/ai-impersonation-scams-exploding-how-to-spot-and-stop/",
    "https://www.juniperresearch.com/research/fintech-payments/fraud-security/merchant-fraud-prevention-research-report/",
    "https://www.ftc.gov/business-guidance/blog/2025/04/celebrating-impersonation-rule-helps-ftc-fight-scams",
    "https://www.mcafee.com/ai/news/ai-voice-scam/#:~:text=and%2077%25%20of%20those%20victims%20said%20they%20lost%20money%20as%20a%20result.",
    "https://www.helpnetsecurity.com/2024/02/05/deepfake-video-conference-call/#:~:text=After%20the%20call%2C%20the%20scammers%20delivered%20additional%20instructions%20via%20IM%2C%20emails%20and%20one%2Don%2Done%20video%20calls.%20As%20instructed%2C%20the%20employee%20sent%20a%20total%20of%20HK%24200%20million%20to%20five%20local%20bank%20accounts.",
    "https://www.sundaypost.com/fp/ai-scam-sweatshops/",
    "https://hubs.la/Q03klgSR0",
    "https://www.techcrunch.com/2024/10/28/wiz-ceo-says-company-was-targeted-with-deepfake-attack-that-used-his-voice/",
    "https://grandviewresearch.com/industry-analysis/conversational-ai-market-report#:~:text=The%20global%20conversational%20AI%20market%20size%20was%20estimated%20at%20USD%2011.58%20billion%20in%202024%20and%20is%20projected%20to%20reach%20USD%2041.39%20billion%20by%202030%2C",
    "https://www.reportfraud.ftc.gov",
    "https://www.cybernews.com/news/deepfake-video-conference-call-hong-kong/#:~:text=Deepfake%20technology%20was%20used%20to%20turn%20publicly%20available%20video%20and%20other%20footage%20of%20staff%20members%20into%20convincing%20meeting%20participants.%20The%20entire%20episode%20lasted%20a%20week.",
    "https://www.sundaypost.com/fp/ai-scam-sweatshops",
    "https://www.idtheftcenter.org/post/2025-trends-in-identity-report-impersonation-scams-rise",
    "https://crif.com/knowledge-events/resources/chatbots-arent-your-friend-so-be-careful-what-you-share/#:~:text=Fraudulent%20AI%20and%20chatbots%20are%20crafted%20to%20mimic%20legitimate%20services%2C%20and%20are%20often%20indistinguishable%20from%20their%20authentic%20counterparts%20to%20the%20untrained%20eye.",
    "https://ftc.gov/news-events/news/press-releases/2025/04/ftc-highlights-actions-protect-consumers-impersonation-scams#:~:text=In%20the%20first%20year%20since%20the%20Rule%20went%20into%20effect%2C%20the%20FTC%20has%20brought%20five%20cases%20involving%20alleged%20violations%20and%20shut%20down%2013%20websites%20that%20were%20illegally%20impersonating%20the%20Commission%20online.",
    "https://www.juniperresearch.com/research/fintech-payments/fraud-security/merchant-fraud-prevention-research-report",
    "https://heimdalsecurity.com/blog/ai-impersonation-scams-exploding-how-to-spot-and-stop",
    "https://techcrunch.com/2024/10/28/wiz-ceo-says-company-was-targeted-with-deepfake-attack-that-used-his-voice",
    "https://sundaypost.com/fp/ai-scam-sweatshops/#:~:text=Advice%20Direct%20Scotland%20said%20international%20fraudsters%20are%20creating%20sophisticated%20scams%20in%20under%20two%20minutes%20using%20freely%20available%20AI%20apps%20such%20as%20ChatGPT.",
    "https://ftc.gov/business-guidance/blog/2025/04/celebrating-impersonation-rule-helps-ftc-fight-scams",
    "https://www.heimdalsecurity.com/blog/ai-impersonation-scams-exploding-how-to-spot-and-stop/",
    "https://www.ctvnews.ca/toronto/article/its-scary-3-ontario-men-lose-373000-to-crypto-investment-fraud",
    "https://www.hubs.la/Q03klgSR0",
    "https://cnet.com/personal-finance/ai-voice-clones-let-scammers-spoof-your-loved-ones-and-take-your-money/#:~:text=Scammers%20need%20as%20little%20as%203%20seconds%20to%20make%20a%20decent%20simulation%20of%20a%20voice%2C%20according%20to%20the%20McAfee%20study.",
    "https://eftsure.com/blog/cyber-crime/these-7-deepfake-ceo-scams-prove-that-no-business-is-safe/#:~:text=But%20in%20early%202024%2C%20an%20employee%20received%20calls%2C%20texts%2C%20and%20voicemail%20from%20someone%20impersonating%20the%20company%27s%20CEO%20on%20WhatsApp.",
    "https://sundaypost.com/fp/ai-scam-sweatshops/",
    "https://ctvnews.ca/toronto/article/its-scary-3-ontario-men-lose-373000-to-crypto-investment-fraud/",
    "https://idtheftcenter.org/post/2025-trends-in-identity-report-impersonation-scams-rise/",
    "https://mcafee.com/ai/news/ai-voice-scam/#:~:text=70%25%20of%20people%20in%20our%20worldwide%20survey%20said%20they%20weren%E2%80%99t%20confident%20they%20could%20tell%20the%20difference%20between%20a%20cloned%20voice%20and%20the%20real%20thing",
    "https://www.heimdalsecurity.com/",
    "https://www.heimdalsecurity.com",
    "https://heimdalsecurity.com",
    "https://zdnet.com/article/ai-unleashes-more-advanced-scams-heres-what-to-look-out-for-and-how-to-stay-protected/#:~:text=Bad%20actors%20can%20use%20this%20capability%20to%20create%20fraudulent%20websites%20that%20are%20visually%20indistinguishable%20from%20real%20ones%20with%20AI%2Dgenerated%20product%20descriptions%2C%20images%2C%20and%20even%20reviews.",
    "https://www.futurecio.tech/ai-assisted-scams-on-the-rise-targeting-e-shoppers-and-job-seekers/#:~:text=Microsoft%27s%20latest%20Cyber%20Signals%20report%20reveals%20AI%2Dassisted%20scams%20targeting%20e%2Dshoppers%20and%20job%20seekers.%C2%A0",
    "https://idtheftcenter.org/wp-content/uploads/2025/06/2025-ITRC-Trends-in-Identity-Report.pdf",
    "https://ftc.gov/news-events/news/press-releases/2025/04/ftc-highlights-actions-protect-consumers-impersonation-scams#:~:text=Impersonation%20scams%20are%20among%20the%20top%20reported%20frauds%20to%20the%20FTC%2C%20with%20losses%20totaling%20%242.95%20billion%20in%202024",
    "https://helpnetsecurity.com/2024/02/05/deepfake-video-conference-call/#:~:text=After%20the%20call%2C%20the%20scammers%20delivered%20additional%20instructions%20via%20IM%2C%20emails%20and%20one%2Don%2Done%20video%20calls.%20As%20instructed%2C%20the%20employee%20sent%20a%20total%20of%20HK%24200%20million%20to%20five%20local%20bank%20accounts.",
    "https://www.readwrite.com/ftc-rule-finalized-governments-and-business-protected-from-ai-impersonation-scams/#:~:text=Further%2C%20the%20FTC%20proposes%20extending%20the%20new%20rule%20that%20safeguards%20governments%20and%20corporations%2C%20adding%20a%20civil%20penalty%20for%20employing%20AI%20to%20impersonate%20people.",
    "https://wilmerhale.com/en/insights/client-alerts/20240223-ftc-proposes-rule-to-make-impersonating-government-entities-and-businesses-unlawful#:~:text=prohibiting%20fraudulent%20impersonation%20of%20governments%2C%20businesses%20and%20their%20officers.",
    "https://trmlabs.com/resources/blog/ai-enabled-fraud-how-scammers-are-exploiting-generative-ai",
    "https://fincen.gov/news/news-releases/fincen-issues-alert-fraud-schemes-involving-deepfake-media-targeting-financial",
    "https://juniperresearch.com/research/fintech-payments/fraud-security/merchant-fraud-prevention-research-report/",
    "https://mcafee.com/ai/news/ai-voice-scam/#:~:text=and%2077%25%20of%20those%20victims%20said%20they%20lost%20money%20as%20a%20result.",
    "https://deloitte.com/us/en/insights/industry/financial-services/deepfake-banking-fraud-risk-on-the-rise.html",
    "https://ftc.gov/news-events/news/press-releases/2025/04/ftc-highlights-actions-protect-consumers-impersonation-scams#:~:text=Companies%20or%20individuals%20that%20violate%20the%20Impersonation%20Rule%20may%20be%20required%20to%20pay%20refunds%20to%20affected%20consumers%20and%20civil%20penalties%20of%20up%20to%20%2453%2C088%20per%20violation.",
    "https://www.securityboulevard.com/2024/08/the-golden-age-of-impersonation-the-dual-role-of-ai-in-cyber-attacks-cyber-defense/#:~:text=Here%E2%80%99s%20the%20reality%20for%20brands%20and%20businesses%3A%20more%20than%2038%2C000%20new%20scam%20pages%20were%20created%20daily%20during%20the%20first%20half%20of%202024%2C%20driven%20primarily%20by%20the%20threat%20actor%E2%80%99s%20desire%20to%20fool%20the%20masses%20with%20greater%20sophistication%20and%20complexity%20with%20hopes%20of%20financial%20gain%20as%20a%20result.%C2%A0",
    "https://ftc.gov/news-events/news/press-releases/2024/09/ftc-announces-crackdown-deceptive-ai-claims-schemes#:~:text=The%20Federal%20Trade%20Commission%20is%20taking%20action%20against%20multiple%20companies%20that%20have%20relied%20on%20artificial%20intelligence%20as%20a%20way%20to%20supercharge%20deceptive%20or%20unfair%20conduct%20that%20harms%20consumers%2C%20as%20part%20of%20its%20new%20law%20enforcement%20sweep%20called%20Operation%20AI%20Comply.",
    "https://signicat.com/the-battle-against-ai-driven-identity-fraud",
    "https://ftc.gov/news-events/news/press-releases/2025/04/ftc-highlights-actions-protect-consumers-impersonation-scams#:~:text=since%20the%20Government%20and%20Business%20Impersonation%20Rule%20took%20effect%20in%20April%202024."
  ],
  "external_images": [],
  "internal_images": [],
  "entities": {
    "persons": [],
    "locations": [],
    "organizations": [
      {
        "name": "Federal Trade Commission",
        "sentiment": "none",
        "tickers": [
          {
            "ticker": null,
            "exchange": null
          }
        ]
      },
      {
        "name": "Grand View Research",
        "sentiment": "none",
        "tickers": [
          {
            "ticker": null,
            "exchange": null
          }
        ]
      }
    ]
  },
  "syndication": {
    "syndicated": false,
    "syndicate_id": null,
    "first_syndicated": false
  },
  "trust": {
    "categories": null,
    "top_news": [],
    "bias": null,
    "source": {
      "type": "local_news",
      "city": [
        "Wallis",
        "South Frydek",
        "Sealy",
        "Santel"
      ],
      "state": [
        "Texas"
      ],
      "country": [
        "US"
      ],
      "domain_type": null,
      "agency": null,
      "organization_name": null
    }
  },
  "rating": null,
  "crawled": "2025-08-14T12:07:41.548+03:00",
  "updated": "2025-08-14T12:19:27.000+03:00"
}